---
title: "v1 of the new workflow: to be shared with VIT by January 15th, 2023"
author: "Aarsh (aarshbatra@uchicagotrust.org/aarshbatra.in@gmail.com)"
date: '2022-10-18'
output: html_document
---

# setup
```{r setup}
knitr::opts_chunk$set(echo = FALSE)
# start time
start_time <- Sys.time()

# load libraries
library(raster)
library(rgdal)
library(dplyr)
library(readr)
library(ncdf4)
library(assertthat)
library(fasterize)
library(sf)
library(SpaDES)
library(foster) # for matching resolution of 2 different rasters
library(DBI) # for connecting R with Postgres
library(RPostgres)
library(ggplot2)
library(RPostgres)
# library(sparklyr)
library(data.table)
library(stringr)

# global variables (check for updates, if any)
who_pm2.5_standard <- 5 # in micrograms per cubic meter, annual average PM2.5 standard
aqli_lyl_constant <- 0.098
india_pm2.5_standard <- 40 # in micrograms per cubic meter
region_pm2.5_standard <- 15 # China

# helpful functions
`%notin%` <- Negate(`%in%`)
source("./R/sat.data.processing.general.helper.R")

print("Libraries and Global variables loaded in.")

```

#> Using the new workflow, generate gadm level 2 population weighted pollution and life years lost numbers (WHO and National Standard) for a given year's Global data. Standalone, uses its own data files, not the data files from the second chunk up top.

# set paths

```{r set_paths, echo=FALSE}

#> paths and global variables (create the necessary folder structure after reading through the paths section. All paths are relative to your current working directory, but you might need to make a few folders, for e.g. for specific resolution datasets). After that, run this script and everything should run smoothly.----------------------------------------

# pollution
pol_data_location <-"./ar.2023.update.using.2021.pol.data/data/input/pollution/0.01x0.01/GWRPM25-NoDust-NoSeaSalt_0.01_0.01/GWRPM25-NoDust-NoSeaSalt/Annual/"



# population
pop_data_location <- "./ar.2023.update.using.2021.pol.data/data/input/population/"
pop_data_file_name <- "landscan-global-2021.tif"



#> shapefiles

# general shape file folder location
shp_files_location <- "./ar.2023.update.using.2021.pol.data/data/intermediate/1_population_and_colormap/1_shapefile_aggregate/"

# gadm2 shape file location
colormap_location <- "colormap/colormap.shp"

# hover map shape file location (not using this year)
hovermap_location <- "hover/hover.shp"

# gadm0 shape file location
gadm0_shp_file_location <- "colormap_collapsed_gadm0/aqli_gadm2_collapse_to_gadm0.shp" 

# gadm1 shape file location
gadm1_shp_file_location <- "colormap_collapsed_gadm1/aqli_gadm2_collapse_to_gadm1.shp" 


#> raster resolution of the final data brick (containing a rasterized pollution, population and a rasterized shape file)
raster_res <- 0.008

# data timeline (note)
pol_data_start_year <- 1998
update_year <- 2021

# data levels
gadm0_folder_name <- "gadm_0"
gadm1_folder_name <- "gadm_1"
gadm2_folder_name <- "gadm_2"

# corresponnding aqli report publishing year (this is the year in which "update_year"'s data will be published. Current lag is 2 years).
report_publishing_year <- 2023

# ssd aqli folder high res (0.01 as in December, 2022) location (use ssd for high writing speeds, hdd's suck)

# drive location
ssd_drive <- "D:/"

# data folder name (on ssd)
aqli_data_share_folder_name <- "aqli.2023.report.data.share"

# high res data location
ssd_location_rasterized_data_0.008 <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".data", "/rasterized/", raster_res, "/", sep = "")

# updated national standards file location and file name
national_standards_pm2.5_jan_2023_location <- "./ar.2023.update.using.2021.pol.data/data/input/standards/" 

national_standards_pm2.5_jan_2023_file_name <- "country_annual_average_pm2.5_standards_asInJan2023.csv"

national_standards_pm2.5_june_2023_file_name <- "country_annual_average_pm2.5_standards_asInJune2023.csv"


#> collapsed data path: gadm0 level
ssd_location_collapsed_gadm0_data_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", gadm0_folder_name, "/", sep  = "")

#> collapsed data path: gadm1 level
ssd_location_collapsed_gadm1_data_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", gadm1_folder_name, "/", sep  = "")

#> collapsed data path: gadm2 level
ssd_location_collapsed_gadm2_data_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", gadm2_folder_name, "/", sep  = "")

#> na population regions processed folder path

na_pop_regions_folder_name <- "na_population_gadm2_regions_resamp_to_0.001_processed"

na_pop_regions_folder_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", na_pop_regions_folder_name , "/", sep  = "")

#> missing regions processed folder path
missing_regions_folder_name <- "missing_gadm2_regions_resamp_to_0.001_processed"

missing_regions_folder_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", missing_regions_folder_name , "/", sep  = "")

#> pov files folder path

pov_files_folder_name <- "pov_files"

pov_files_folder_path <- stringr::str_c(ssd_drive, aqli_data_share_folder_name, "/", report_publishing_year, ".publish.Year.with.", update_year, ".", "data", "/collapsed/", pov_files_folder_name , "/", sep  = "")

#-------------------------------------------------

```



# main pipeline to get yearly gadm2 and high res pollution datasets

```{r get_yearly_pol_datasets, echo=FALSE}

# benchmarking
threshold_0 <- Sys.time() 

# population raw data
population_dataset <- raster::raster(str_c(pop_data_location, pop_data_file_name, sep = ""))

# naming the raw global landscan population data and setting its crs to be the same as the pollution data
raster::crs(population_dataset) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
names(population_dataset) <- "population"


#--- no longer need to crop, as this can be reused, so I wrote it as a tif, and then will simply read it
#- crop population dataset to the pollution dataset
# pop_raw_landscan_crop_pol <- raster::crop(population_dataset, pollution_dataset)

#- write the cropped population dataset
# pop_raw_landscan_crop_pol %>%
#   raster::writeRaster(filename = "./experimentation/pop_raw_landscan_crop_pol.tif", 
#                       format = "GTiff", overwrite = TRUE)
#---

# reading in the pre-cropped population raster, which remains the same for all pollution datasets
pop_raw_landscan_crop_pol <- raster::raster("./experimentation/pop_raw_landscan_crop_pol.tif")


# load latest colormap shapefile for (last complete updated: November, 2022)
colormap <- sf::st_read(str_c(shp_files_location, colormap_location, sep = ""))

#-- this remains same for all pollution datasets, hence writing it, and will then simply read it
# polygon_cells <- fasterize(colormap, pol_0.01_region_in_landscan_pop_res, field = "objectid", fun = "last")
# writeRaster(polygon_cells,
# 	filename = "./experimentation/colormap_rasterized.tif",
# 	format = "GTiff", overwrite = TRUE)
#---

polygon_cells <- raster::raster("./experimentation/colormap_rasterized.tif")

# making sure that the crs of the rasterized shapefile is the same as the 0.008 population and pollution rasters. 
raster::crs(polygon_cells) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

# benchmarking
threshold_1 <- Sys.time() 

print("All raw datasets read into R.")

#> reading pollution data, one year at a time and then will concatenate all results-----------------------
# Note that the datasets in this pipeline do not include the  geometry column. That can be added in the end after concatenating all yearly datasets into a single final gadm2 dataset. For the gadm0 and gadm1 datasets (which will be derived from the single "final gadm2 dataset"), a similar process will follow.

# pol data list
pol_data_list <- list.files(pol_data_location) %>% sort()

# pollution column names empty vector
pol_col_name_vec <- c()

#> for loop begins----------------------------------------------------------------

print("For loop begins: Processing pollution rasters 1 year at a time")

for (i in 1:length(pol_data_list)){
  
  # benchmarking
  threshold_1.5 <- Sys.time()
  
  print(stringr::str_c("Iteration #", i, "/", (update_year - pol_data_start_year) + 1, " begins"))
  
  pol_col_name_vec[i] <- str_c("pm", (pol_data_start_year + (i-1)))
  
  # for testing purposes
  # if(i < 12){
  #   next
  # }
  
  # if(i > 3){
  #   break
  # }
  
  # pollution file name given the current iteration
  cur_pol_file_name <- pol_data_list[i]
  
  # cur pollution file year
  cur_pol_file_year <- stringr::str_extract(str_extract(cur_pol_file_name, "(\\d+)-(\\d+)"), "....")
  
  # read in the pollution raster for a given year
  pollution_dataset <- raster::raster(str_c(pol_data_location, cur_pol_file_name, sep = ""))
  
  # naming the raw global pollution data and setting its crs
raster::crs(pollution_dataset) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
names(pollution_dataset) <- "pm2.5_pollution"


# benchmarking
threshold_2 <- Sys.time() 

# matching the resolution of the cropped population and pollution datasets
pol_0.01_region_in_landscan_pop_res <- foster::matchResolution(pollution_dataset, pop_raw_landscan_crop_pol)

# benchmarking
threshold_3 <- Sys.time() 

print("stacking all layers in a raster brick")

# creating a raster brick using the population and pollution data
region_raster_brick <- pop_raw_landscan_crop_pol %>% 
  raster::addLayer(pol_0.01_region_in_landscan_pop_res) 

# setting the names of the newly created placheolders
names(region_raster_brick) <- c("population", "pm2.5_pollution")

# set the same crs for pollution brick
raster::crs(region_raster_brick) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

print("Population and pollution layers matched")

# benchmarking
threshold_4 <- Sys.time() 

# Now match each population/pollution point to a colormap polygon. To do this, convert
# polygons to raster of same resolution as population raster, with value of each cell equal
# to objectid of polygon that covers its center.
# Fasterize is an ultra-fast version of the rasterize function.

# add rasterized colormap to the raster brick
region_raster_brick <- region_raster_brick %>% 
  raster::addLayer(polygon_cells)

print("added rasterized colormap layer to the brick")

names(region_raster_brick)[length(names(region_raster_brick))] <- "colormap_objectid"

# benchmarking
threshold_5 <- Sys.time() 

# from this point forward, replace all instances of "region_raster_brick_df" with "aqli_raster_brick_df". Make sure that to make this update in all previous branches. If you are reading this, and if other branches still exist at this point. Make sure to make this update in those branches (even though you might end up using just this branch, its good to make that change).
aqli_raster_brick_df <- raster::as.data.frame(region_raster_brick)

print("raster brick converted to data frame")

# write rasterized dataframe to ssd, in arrow data format (0.008x0.008 resolution)
aqli_raster_brick_df %>% arrow::write_dataset(str_c(ssd_location_rasterized_data_0.008, cur_pol_file_year, ".parquet"))

# benchmarking
threshold_6 <- Sys.time() 

#-- (Update: no longer needed as we directly coerce region_raster_brick_df to an arrow table). Will only need to write this when implementing high res layer.
#- write region_raster_brick_df to a csv
#--

# from this point forward, replace all instances of "pollution_data_0.01_light" with "aqli_raster_brick_light". Make sure that to make this update in all previous branches. If you are reading this, and if other branches still exist at this point. Make sure to make this update in those branches (even though you might end up using just this branch, its good to make that change).
aqli_raster_brick_light <- arrow::as_arrow_table(aqli_raster_brick_df)

# benchmarking
threshold_7 <- Sys.time() 

print("rasterized dataframe coerced to an arrow table")

#-- read raster data using arrow (no longer needed as we already coerced region_raster_brick_df to an arrow table)
# aqli_raster_brick_light <- arrow::open_dataset("./experimentation/pollution_data_0.01_2021.csv", format = "csv")
#-- 


# from this point forward, replace all instances of "pollution_district_wise" with "aqli_gadm2_collapse". Make sure that to make this update in all previous branches. If you are reading this, and if other branches still exist at this point. Make sure to make this update in those branches (even though you might end up using just this branch, its good to make that change).
aqli_gadm2_collapse <- aqli_raster_brick_light %>%
  dplyr::filter((!is.na(colormap_objectid)) & ((as.character(colormap_objectid) != "NA"))) %>%
  dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         pollution_pop_weighted = pop_weights*pm2.5_pollution) %>%
  dplyr::summarise(total_population = sum(population, na.rm = TRUE), 
            avg_pm2.5_pollution = sum(pollution_pop_weighted, na.rm = TRUE)) %>%
  dplyr::ungroup() %>%
  dplyr::rename(objectid_gadm2 = colormap_objectid)

# renaming the pollution column such that it includes the year in question
colnames(aqli_gadm2_collapse)[str_detect(colnames(aqli_gadm2_collapse), "avg_pm2.5_pollution")] <- pol_col_name_vec[i]

# writing the gadm2 level dataset to ssd
aqli_gadm2_collapse %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm2_data_path, cur_pol_file_year, "_", gadm2_folder_name, ".csv"))

# benchmarking
threshold_8 <- Sys.time() 



print(stringr::str_c("Iteration #", i, "/", (update_year - pol_data_start_year) + 1, " end"))

print("Freeing memory before proceeding to next iteration")

# benchmarking
threshold_9 <- Sys.time()

# collect garbage, free memory
gc()

# benchmarking
threshold_10 <- Sys.time()

# time it took to complete the current iteration

print(str_c("Time taken to complete iteration # ", i, "/", (update_year - pol_data_start_year) + 1, ": ", threshold_10 - threshold_1.5))

}

end_time_main_pipeline <- Sys.time()
time_diff <- end_time_main_pipeline - start_time

print(str_c("Total time taken (main pipeline for loop) with ", i, " years of pollution data processed: ", time_diff))

#> for loop ends-----------------------------------------------------------------------


```

# combine all pollution yearly datasets into a single gadm2 dataset, in the format that has to be shared with VIT. See AQLI data dictionary for more information.

```{r combine_yearly_pol_data, echo=FALSE}

#---------
#> Note: if you have already processed the pollution datasets in the above chunk and just want to run the combining code in this chunk, make sure to uncomment the following code and run it before proceeding to get the colormap and pol_col_name_vec. Also, make sure to run the "setup" and "set path" chunks. If you have already run the above chunks, then you would already have these objects and in that case there is no need to run the below commented code.

# # load latest colormap shapefile for (last complete updated: November, 2022)
# colormap <- sf::st_read(str_c(shp_files_location, colormap_location, sep = ""))
# 
# # generate the pol_col_name_vec
# pol_col_name_vec <- c()
# for(i in 1:24){
#      pol_col_name_vec[i] <- str_c("pm", (pol_data_start_year + (i-1)))
#  }

#-----------

# benchmarking
threshold_11 <- Sys.time() 

#> Output in VIT data sharing format

# read in all pollution data and name_0, name_1, name_2 columns from colormap (joined in the first iteration of the loop below) into a single dataset, with just pollution columns. I am in the process of updating national standards, so for now we have a placeholder national standards column, which is just set to 10 micrograms per cubic meter for all regions. The updated national standards column will be added alongside the life years lost columns after the below for loop.

# list of files in the collapsed folder
collapsed_gadm2_files_vec <- list.files(str_c(ssd_location_collapsed_gadm2_data_path)) %>% 
  sort() 

# indices of the relevant files (from the above vector) needed for combining.
collapsed_gadm2_files_vec_rel_ind <- str_detect(collapsed_gadm2_files_vec, ".csv")

# keeping only relevant files that will be combined below
collapsed_gadm2_files_vec_rel_files <- collapsed_gadm2_files_vec[collapsed_gadm2_files_vec_rel_ind]

for(i in 1:length(collapsed_gadm2_files_vec_rel_files)){
  if(i == 1){
    temp_gadm2 <- readr::read_csv(str_c(ssd_location_collapsed_gadm2_data_path, collapsed_gadm2_files_vec_rel_files[i]))
    
    aqli_gadm2_collapse_master <- temp_gadm2 %>%
      dplyr::left_join(colormap, by = c("objectid_gadm2" = "objectid")) %>%
      dplyr::mutate(whostandard = 5, 
             natstandard = 10) %>%
      dplyr::select(objectid_gadm2, iso_alpha3, NAME_0, NAME_1, NAME_2, total_population,
             whostandard, natstandard,
             pol_col_name_vec[i]) %>%
      dplyr::rename(country = NAME_0,
             name_1 = NAME_1, 
             name_2 = NAME_2,
             population = total_population)
    
    colnames(aqli_gadm2_collapse_master)[ncol(aqli_gadm2_collapse_master)] <- pol_col_name_vec[i]
    
  } else{
     temp_gadm2 <- readr::read_csv(str_c(ssd_location_collapsed_gadm2_data_path, collapsed_gadm2_files_vec_rel_files[i]))
    
    aqli_gadm2_collapse_master <- aqli_gadm2_collapse_master %>% 
      dplyr::left_join(temp_gadm2, by  = "objectid_gadm2") %>%
      dplyr::select(-c(total_population)) %>%
      dplyr::select(objectid_gadm2, iso_alpha3, country, name_1, name_2, population, whostandard, natstandard, pol_col_name_vec[1:(i-1)],
             pol_col_name_vec[i])
    
    colnames(aqli_gadm2_collapse_master)[ncol(aqli_gadm2_collapse_master)] <- pol_col_name_vec[i]
  
  }
}

#> write aqli_gadm2_collapse_master df's current version (which does not include the missing regions and also does not capture the na pop regions that we will do next). Next step will be to capture the na population regions (by that I don't mean regions with NA in the population column (no such regions exist), but rather regions where population = 0) and missing regions and then finally we'll incorporate them in the aqli_gadm2_collapse_master and write that final version later.

aqli_gadm2_collapse_master %>%
    readr::write_csv(str_c(ssd_location_collapsed_gadm2_data_path, "[missingAndNAPopRegionsNotYetIncorporatedVersion]master_global_allyears_gadm2_non_geom.csv"))

#> missing regions and zero population gadm2 capture using the regional_summary function (by resampling to a resolution of 0.001) from the helper file in the R sub-directory and adding them back into the aqli_gadm2_collapse_master object, before continuing to add life years lost columns to it.------------------

# If, not running the pipeline from scratch, use the already written gadm2_aqli dataset and uncomment the below block, otherwise use aqli_gadm2_collapse_master.

# gadm2_aqli_2021 <- readr::read_csv("./ar.2023.update.using.2021.pol.data/data/output_vit/gadm2_aqli2021_vit.csv")

# NA pop regions object ids
# objectid_gadm2_na_pop <- gadm2_aqli_2021 %>%
#   filter(is.na(population)) %>%
#   pull(objectid_gadm2) %>%
#   as.vector()

# NA pop regions object ids
objectid_gadm2_na_pop <- aqli_gadm2_collapse_master %>%
  filter(population == 0) %>%
  pull(objectid_gadm2) %>%
  as.vector()

# processing all NA pop regions and outputting a single dataset for all regions containing pollution info for all years

res_resample_to <- 0.001 # mention the resolution to which the na pop region is to be resampled.
res_resample_from <- 0.00833333 # mention the current resoltion 
start_year <- 1998 # mention start year, usually the same as the first year for which the AQLI data is available.

na_pop_regions_processed <- regional_summary(colormap, pol_data_location, pop_raw_landscan_crop_pol, res_resample_to,objectid_gadm2_na_pop, start_year, res_resample_from)

# adding a temporary national standard column to the na_pop_regions_processed dataset so that it matches the aqli_gadm2_collapse_master dataset

na_pop_regions_processed <- na_pop_regions_processed %>%
  mutate(natstandard = NA) %>%
  select(objectid_gadm2:whostandard, natstandard, everything())

# write the na pop regions processed df to ssd's relevant folder

na_pop_regions_processed %>% 
  write_csv(str_c(na_pop_regions_folder_path, "na_pop_regions_processed.csv"))

## filter out those regions whose population doesn't make sense (limitation of the current resampling pipeline, need to resolved in future updates)

# # calculating area of the 97 na population regions (sanity check)
# na_pop_regions_colormap <- colormap %>%
#   filter(objectid %in% objectid_gadm2_na_pop)
# 
# # calculating area for the above regions, after transforming to crs 4326
# na_pop_regions_colormap <- st_transform(na_pop_regions_colormap, 4326)
# na_pop_regions_colormap <- st_make_valid(na_pop_regions_colormap)
# 
# # creating a new column that will measure area in square kilometers
# na_pop_regions_colormap$area <- as.numeric(st_area(na_pop_regions_colormap)/(10^6))
# 
# # creating a new column that displays area without units
# na_pop_regions_colormap <- na_pop_regions_colormap %>%
#   mutate(area_sans_units = as.numeric(area)) %>%
#   st_drop_geometry()


## post finalizing the na pop regions that are to be included, now getting the missing regions

# read in 2021 processed aqli gadm2 data (only do this if running this specific bit of the pipeline), otherwise use the aqli_gadm2_collapse_master dataset
# aqli_2021_gadm2_test <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_vit/gadm2_aqli2021_vit.csv")

# get indices for missing areas
missing_ids_index <- colormap$objectid %notin% aqli_gadm2_collapse_master$objectid_gadm2

# missing areas
missing_areas <- colormap[missing_ids_index, ]

# calculating areas for missing areas and filetering areas whose area is less than or equal to  a threshold
missing_areas <- st_transform(missing_areas, 4326)
missing_areas <- st_make_valid(missing_areas)

# creating a new column called area
missing_areas$area <- as.numeric(st_area(missing_areas)/(10^6))

# create a non-geom version of the dataset
missing_areas_drop_geom <- missing_areas %>%
  mutate(area_sans_units = as.numeric(area)) %>%
  st_drop_geometry()

# regions that we expect to be missing and filtering them out of the above list
missing_regions_exp_to_be_missing <- readxl::read_xlsx("C:/Users/Aarsh/Desktop/others/part-1_expectToBeMissing.xlsx")

# # regions we don't expect to be missing according to the csv (the method right below, is more accurate way to get the 153 - 70 regions that we don't expect to be missing).
# missing_regions_dont_expect_missing <- missing_areas_drop_geom %>%
#   filter(NAME_0 %notin% missing_regions_exp_to_be_missing$NAME_0 & 
#         NAME_1 %notin% missing_regions_exp_to_be_missing$NAME_1 &
#         NAME_2 %notin% missing_regions_exp_to_be_missing$NAME_2)

# regions that we don't expect to be missing according to the object ids (this will give us the 83 regions that we don't expect to be missing). Post that, I'll remove a 5 other regions by feeding in object ids that I know are outside the bounds of the ACAG pm2.5 data limits (). As of now, this part of code requires human intervention and a bit of testing around (every year this bit would have to be manually changed, e.g. the area threshold in the filter command below), but I am thinking of a better way to automate this.
missing_regions_dont_expect_missing_objid <- missing_areas_drop_geom %>%
  filter(area_sans_units < 245.9) %>%
  filter(objectid %notin% c(28044, 28048, 28063, 35561, 35567)) %>%
  pull(objectid) %>%
  as.vector()

# capture missing regions and add a temporary natstandard column that will be updated later on
missing_regions_capture <- regional_summary(colormap, pol_data_location, pop_raw_landscan_crop_pol, res_resample_to,missing_regions_dont_expect_missing_objid, start_year, res_resample_from)

missing_regions_capture <- missing_regions_capture %>%
    mutate(natstandard = NA) %>%
  select(objectid_gadm2:whostandard, natstandard, everything())

# missing regions captured write to ssd
missing_regions_capture %>%
   write_csv(str_c(missing_regions_folder_path, "missing_regions_processed.csv"))

## store objectids of all resampled/captured (to a resolution of 0.001) na population regions in a vector (already present in the gadm2 collapsed file and will replace their old version). 16/97 na pop regions have been captured. For the ones, not captured, improvements will be made to this pipeline in the future. The reason might be that to capture the coordinates more precisely (more decimal points) because when capturing tiny regions, this level precision matters. All in all 99.8089% of the regions have been captured. A couple notes (on some regions that were manually dropped): na_pop_regions_dropped_obj_ids (if no specific comments mentioned, means population is 0 and as a result pollution was 0): 25050 (pop avialable, but all pollution  columns are 0, weird), 35356 (population is 0, but all pollution columns are available, more weirder), 37791 (population is available, but all pollution data columns are missing), 42205 (zero population, but all pollution columns are available). Only kept rows where both population and atleast one pollution column is available.

## store objectids of all resampled (to a resolution of 0.001) missing regions, that we don't expect to be missing, in a vector (not present in the current gadm2 collapsed file, and will be appended to the file after na pop regions have been replaced. Post that sort by objectid_gadm2). 47/83 missing regions (that we don't expect to be missing) have been captured. The remaining 70 regions, we do expect to be missing are missing because they are either above ~67 degree N, or below ~ 55 degree south. Again, for the ones, not captured, improvements will be made to this pipeline in the future. The reason might be that to capture the coordinates more precisely (more decimal points) because when capturing tiny regions, this level precision matters. A couple notes on some regions that were manually dropped: missing_regions_non_zero_pop_dropped_obj_ids: 2079 (population available, but all pollution columns are 0), 25046 (population available, but all pollution columns are 0), 29681 (population available, but all pollution columns are 0), 34362 (population is 0, but all pollution columns are available), 34646 (pop was 13, pollution data was available, but pop was too low), 34834 (pop was 3 and pollution data is available, but pop was too low), 34884 (pop was 9 and pollution data was available, but population value is too low), 34893 (pop was 2 and pollution columns are available, but population value was too low), 35019 (pop was 8, pollution column data are available, but pop was too low), 35024 (0 pop, but all pollution columns are available), 35160 (0 pop, but all pollution columns are available), 35582 (0 pop, but all pollution columns are available), 35016 (pop was avail, but all pollution columns are 0), 35589 (pop 56, all pollution columns available, but pop was too low), 35603 (pop 1, all pollution columns available, but pop was too low), 36393 (pop 1, all pollution columns available, but pop was too low), 36436 (pop 4, all pollution columns available, but pop was too low), 36828 (pop was 8, and all pollution columns are available, but pop was too low). Only kept rows where both population and atleast one pollution column is available.

# The regions that were manually dropped have been explained below.

# a subset of the above na pop regions and missing regions that have been saved have populations that are not captured very well, open those csv's in excel and browse through them and get rid of populations that seem super unreasonable (e.g. a population of 1 for a huge region). This part as of now is manual, but I am thinking of ways to automate it. It's not just that rows with population below a certain number can be eliminated, it's more subtle than that, so need to think about that a little and implement a more elegant way to do this bit in the future. Note that, in the na pop regions and missing regions folder on the ssd, there will be 2 versions of each. One with all regions, and the other one (will have the word "handpicked" in the file name), with handpicked regions. Read in the handpicked regions below.

# Before the incorporation of missing and na pop regions we had 48059 unique object ids in gadm 2 (including 97 na pop regions). Now removing the 97 na pop regions and replaing them with 16 filled pop regions and 47 regions that were previously missing, brings the final count of object ids to 48025 (48059 - 97 + 16 + 47). All in all 99.61213% (48025/48212) of the regions have been captured, where 48212 are the total number of objectids in the latest colormap shapefile.

na_pop_regions_processed_handpicked <- read_csv(str_c(na_pop_regions_folder_path, "na_pop_regions_processed_handpicked.csv"))

missing_regions_processed_handpicked <- read_csv(str_c(missing_regions_folder_path, "missing_regions_processed_handpicked.csv"))


na_pop_regions_processed_handpicked_obj_ids <- na_pop_regions_processed_handpicked$objectid_gadm2

aqli_gadm2_collapse_master <- aqli_gadm2_collapse_master %>%
  filter(objectid_gadm2 %notin% na_pop_regions_processed_handpicked_obj_ids) %>%
  bind_rows(na_pop_regions_processed_handpicked) %>%
  bind_rows(missing_regions_processed_handpicked) %>%
  filter(population != 0) %>%
  arrange(objectid_gadm2)

#-----------------------------------------------------------------

# benchmarking
threshold_12 <- Sys.time() 

#> add in the updated national standards column (last updated: January 18, 2023 by Aarsh) and bring it in appropriate "join ready" format (to be joined with the combined pollution data before adding life years lost columns)

# reading in the national standards file (to do: add in (if missing) the national standards of the missing and zero pop regions captured above.)
national_standards_pm2.5 <- readr::read_csv(stringr::str_c(national_standards_pm2.5_jan_2023_location, national_standards_pm2.5_jan_2023_file_name, sep = ""))

# keeping and renaming relevant columns
national_standards_pm2.5 <- national_standards_pm2.5 %>%
  dplyr::select(country, natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1) %>%
  dplyr::rename(natstandard_updated = natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1)

# replacing the national standards column of the aqli_gadm_collapse_master file (output of the above for loop) with the updated national standards column
aqli_gadm2_collapse_master <- aqli_gadm2_collapse_master %>%
  dplyr::left_join(national_standards_pm2.5, by = "country") %>%
  dplyr::select(-c(natstandard)) %>%
  dplyr::select(objectid_gadm2:whostandard, natstandard_updated, dplyr::everything()) %>%
  dplyr::rename(natstandard = natstandard_updated)

# replace natstandard == "No national standard", with natstandard == 0, and then changing its data type to "numeric"
aqli_gadm2_collapse_master <- aqli_gadm2_collapse_master %>%
  dplyr::mutate(natstandard = ifelse(natstandard == "No national standard", 0, natstandard))

aqli_gadm2_collapse_master$natstandard <- as.numeric(aqli_gadm2_collapse_master$natstandard)
  
# adding in the life years lost columns and doing some basic cleaning of column names to bring it into the format that we want, as per the AQLI data dictionary

aqli_gadm2_collapse_master <- aqli_gadm2_collapse_master %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, name_1, name_2, population, whostandard, natstandard, everything()) %>%
    dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
    dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))

# benchmarking
threshold_13 <- Sys.time() 

# write the above (non-geometry version) of gadm2 master file to the collapsed/gadm2 folder (this version incorporates the na pop and missing regions, but only partially incoroporate ViT column name changes request). Full changes version as requested by ViT will be written at the end of this chunk for all 3 levels (both geom and non-geom versions)

aqli_gadm2_collapse_master %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm2_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_non_geom.csv"))

#> add in the geometry column by left joining the above with a color file and then write that to the collapsed/gadm2 folder

# joining the gadm2 collapse master file with colormap (using objectid as the joining column), to get the geometry column
aqli_gadm2_collapse_master_with_geom <- aqli_gadm2_collapse_master %>%
  dplyr::left_join(colormap %>% rename(objectid_gadm2 = objectid), by = "objectid_gadm2") %>%
  dplyr::rename(iso_alpha3 = iso_alpha3.x) %>%
  dplyr::select(-c(iso_alpha3.y, NAME_0, NAME_1, NAME_2))

# creating new shortened colnames, before exporting as a shape file, to be compliant with ESRI shapefile column name restrictions. Note that, when reading the shapefile later on, remember to convert the colnames back to how it appears in the "non-geom" version of the gadm2 collapse master dataset, to avoid any confusions.

new_col_names_gadm2_collapse_master_geom_ver <- colnames(aqli_gadm2_collapse_master_with_geom) %>%
  dplyr::as_tibble() %>%
  dplyr::mutate(
         col_names_shortened = str_replace(value, "who", "w"), 
         col_names_shortened = str_replace(col_names_shortened, "nat", "n"), 
         col_names_shortened = str_replace(col_names_shortened, "standard", "stan"), 
         col_names_shortened = str_replace(col_names_shortened, "_", ""), 
         col_names_shortened = str_replace(col_names_shortened, "objectidgadm2", "objidgadm2"), 
         col_names_shortened = str_replace(col_names_shortened, "isoalpha3", "isoal3")) %>%
  dplyr::select(col_names_shortened) %>%
  unlist() %>%
  as.vector()

# assigning new colnames to the geom version of the gadm2 collapse master file
colnames(aqli_gadm2_collapse_master_with_geom) <- new_col_names_gadm2_collapse_master_geom_ver

# making sure to st_as_sf the geom version before exporting to shape file and then exporting the shape file
aqli_gadm2_collapse_master_with_geom <- aqli_gadm2_collapse_master_with_geom %>%
  sf::st_as_sf() 

# write the missing and NA pop region incorporated and ViT column names changes partially incorporated (which will be more than enough for geom version, as it is to be used internally). 

#This warning was issued while writing the shapefile, need to be resolved: In CPL_write_ogr(obj, dsn, layer, driver, as.character(dataset_options): GDAL Message 1: One or several characters couldn't be converted correctly from UTF-8 to ISO-8859-1.  This warning # will not be emitted anymore
  
aqli_gadm2_collapse_master_with_geom %>%
  sf::write_sf(str_c(ssd_location_collapsed_gadm2_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_geom.shp"))

# garbage collection
gc()

#-----------


#> collapse the gadm2 file to gadm0 (country) level and write both geom and non-geom versions to their respective folders

# finalizing the gadm0 level dataset
aqli_gadm0_collapse_from_gadm2 <- aqli_gadm2_collapse_master %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))
  

# write the above (non-geometry version) of gadm0 master file to the collapsed/gadm0 folder (this version incorporates the na pop and missing regions, but only partially incoroporate ViT column name changes request). Full changes version as requested by ViT will be written at the end of this chunk for all 3 levels (both geom and non-geom versions)

aqli_gadm0_collapse_from_gadm2 %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm0_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm0_non_geom.csv"))


# read in the gadm0 shape file (which is collapsed from the colormap) and get it ready for joining with the above summary table

gadm0_shp_file <- sf::st_read(str_c(shp_files_location, gadm0_shp_file_location, sep = ""))

gadm0_shp_file_subset <- gadm0_shp_file %>%
  dplyr::select(-c(NAME_1, NAME_2, objectid, iso_alpha3))

# add in the geometry column by left joining the above with a country level shape file and then write that to the collapsed/gadm0 folder

# joining the gadm0 collapse master file with the country level shapefile (using "country/NAME_0" as the joining column), to get the geometry column

aqli_gadm0_collapse_from_gadm2_with_geom <- aqli_gadm0_collapse_from_gadm2 %>%
  dplyr::left_join(gadm0_shp_file_subset, by = c("country" = "NAME_0")) %>%
  sf::st_as_sf()

# (tbd): creating new shortened colnames, before exporting as a shape file, to be compliant with ESRI shapefile column name restrictions. Note that, when reading the shapefile later on, remember to convert the colnames back to how it appears in the "non-geom" version of the gadm0 collapse master dataset, to avoid any confusions.

new_col_names_gadm0_collapse_from_gadm2 <- colnames(aqli_gadm0_collapse_from_gadm2_with_geom) %>%
  dplyr::as_tibble() %>%
  dplyr::mutate( 
         col_names_shortened = str_replace(value, "who", "w"), 
         col_names_shortened = str_replace(col_names_shortened, "nat", "n"), 
         col_names_shortened = str_replace(col_names_shortened, "standard", "stan"), 
         col_names_shortened = str_replace(col_names_shortened, "_", ""), 
         col_names_shortened = str_replace(col_names_shortened, "objectidgadm0", "objidgadm0"), 
         col_names_shortened = str_replace(col_names_shortened, "isoalpha3", "isoal3")) %>%
  dplyr::select(col_names_shortened) %>%
  unlist() %>%
  as.vector()


# (tbd): assigning new colnames to the geom version of the gadm0 collapse master file
colnames(aqli_gadm0_collapse_from_gadm2_with_geom) <- new_col_names_gadm0_collapse_from_gadm2

# (tbd): making sure to st_as_sf the geom version before exporting to shape file and then exporting the shape file

aqli_gadm0_collapse_from_gadm2_with_geom <- aqli_gadm0_collapse_from_gadm2_with_geom %>%
  sf::st_as_sf()


# write the missing and NA pop region incorporated and ViT column names changes partially incorporated (which will be more than enough for geom version, as it is to be used internally). There were warning related to couple fields whose population values were not successfully written because it was too large a number with respect to the field: "width warning" (GDAL Message 1). Resolve this warning, a screenshot of it is stored in the gadm0 folder under collapsed folder in the ssd.
aqli_gadm0_collapse_from_gadm2_with_geom %>%
  sf::write_sf(str_c(ssd_location_collapsed_gadm0_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm0_geom.shp"))

# garbage collection
gc()

#-----------

#>  collapse the gadm2 file to gadm1 (state/province) level and write both geom and non-geom versions to their respective folders

# finalizing the gadm1 level dataset
aqli_gadm1_collapse_from_gadm2 <- aqli_gadm2_collapse_master %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))
  
  

# write the above (non-geometry version) of gadm1 master file to the collapsed/gadm1 folder (this version incorporates the na pop and missing regions, but only partially incoroporate ViT column name changes request). Full changes version as requested by ViT will be written at the end of this chunk for all 3 levels (both geom and non-geom versions)

aqli_gadm1_collapse_from_gadm2 %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm1_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm1_non_geom.csv"))

# read in the gadm1 shape file (which is collapsed from the colormap) and get it ready for joining with the above summary table

gadm1_shp_file <- sf::st_read(str_c(shp_files_location, gadm1_shp_file_location, sep = ""))


gadm1_shp_file_subset <- gadm1_shp_file %>%
  dplyr::select(-c(NAME_2, objectid, iso_alpha3))

# (tbd) add in the geometry column by left joining the above with a state level shape file and then write that to the collapsed/gadm1 folder

# joining the gadm1 collapse master file with the state level shapefile (using " " as the joining column), to get the geometry column

aqli_gadm1_collapse_from_gadm2_with_geom <- aqli_gadm1_collapse_from_gadm2 %>%
  dplyr::left_join(gadm1_shp_file_subset, by = c("country" = "NAME_0", "name_1" = "NAME_1")) %>%
  sf::st_as_sf()


# (tbd): creating new shortened colnames, before exporting as a shape file, to be compliant with ESRI shapefile column name restrictions. Note that, when reading the shapefile later on, remember to convert the colnames back to how it appears in the "non-geom" version of the gadm1 collapse master dataset, to avoid any confusions.

new_col_names_gadm1_collapse_from_gadm2 <- colnames(aqli_gadm1_collapse_from_gadm2_with_geom) %>%
  dplyr::as_tibble() %>%
  dplyr::mutate( 
         col_names_shortened = str_replace(value, "who", "w"), 
         col_names_shortened = str_replace(col_names_shortened, "nat", "n"), 
         col_names_shortened = str_replace(col_names_shortened, "standard", "stan"), 
         col_names_shortened = str_replace(col_names_shortened, "_", ""), 
         col_names_shortened = str_replace(col_names_shortened, "objectidgadm1", "objidgadm1"), 
         col_names_shortened = str_replace(col_names_shortened, "isoalpha3", "isoal3")) %>%
  dplyr::select(col_names_shortened) %>%
  unlist() %>%
  as.vector()

# (tbd): assigning new colnames to the geom version of the gadm1 collapse master file
colnames(aqli_gadm1_collapse_from_gadm2_with_geom) <- new_col_names_gadm1_collapse_from_gadm2

# (tbd): making sure to st_as_sf the geom version before exporting to shape file and then exporting the shape file

aqli_gadm1_collapse_from_gadm2_with_geom <- aqli_gadm1_collapse_from_gadm2_with_geom %>%
  sf::st_as_sf()

# write the missing and NA pop region incorporated and ViT column names changes partially incorporated (which will be more than enough for geom version, as it is to be used internally). There were warning related to couple fields whose population values were not successfully written because it was too large a number with respect to the field: "width warning" (GDAL Message 1). Resolve this warning, a screenshot of it is stored in the gadm1 folder under collapsed folder in the ssd.

aqli_gadm1_collapse_from_gadm2_with_geom %>%
  sf::write_sf(str_c(ssd_location_collapsed_gadm1_data_path, "[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm1_geom.shp"))

#> For gadm 0, 1 and 2 write the final versions (non-geom version) of files, incorporating all remaining ViT column name changes/drop requests, add notes from the sticky notes (and then remove the sticky notes comment). Geom versions will work without ViT name restrictions as it is to be used internally, and wrap this up!!!.

aqli_gadm2_collapse_master <- read_csv("D:/aqli.2023.report.data.share/2023.publish.Year.with.2021.data/collapsed/gadm_2/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_non_geom.csv")

aqli_gadm1_collapse_from_gadm2 <- read_csv("D:/aqli.2023.report.data.share/2023.publish.Year.with.2021.data/collapsed/gadm_1/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm1_non_geom.csv")

aqli_gadm0_collapse_from_gadm2 <- read_csv("D:/aqli.2023.report.data.share/2023.publish.Year.with.2021.data/collapsed/gadm_0/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm0_non_geom.csv")


# rename: country, name_1, name_2 AND remove iso_alpha3, natstandard, whostandard (and adjusted natstandard column, which has now been incorporated in the above pipeline)
aqli_gadm2_collapse_master_finalized <- aqli_gadm2_collapse_master %>%
  rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) 

aqli_gadm2_collapse_master_finalized %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm2_data_path, "[finalizedApr2023]gadm2_aqli2021_vit.csv"))

# rename: country, name_1 AND remove iso_alpha3, natstandard, whostandard AND replace the current objectid_gadm1 column (which is a grouped serial number) with actual row number wise global serial number, by using row_number() and ungroup(). This step should be taken care of in the above steps, when this dataset is begin created for the first time. Once incorporated there, remove it from here. I found out about it, when I reached this step and will replace it whenever I can. Also adjusted natstandard column, which has now been incorporated in the above pipeline.
aqli_gadm1_collapse_from_gadm2_finalized <- aqli_gadm1_collapse_from_gadm2 %>%
  rename(name0 = country, name1 = name_1) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) %>%
  ungroup() %>%
  mutate(objectid_gadm1 = row_number()) 

aqli_gadm1_collapse_from_gadm2_finalized %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm1_data_path, "[finalizedApr2023]gadm1_aqli2021_vit.csv"))

# rename country to name0 AND remove whostandard, also add an ungroup statement, when this dataset was created up top, to be safe. Also, adjusted natstandard column, which has now been incorporated in the above pipeline.
aqli_gadm0_collapse_from_gadm2_finalized <- aqli_gadm0_collapse_from_gadm2 %>%
  rename(name0 = country) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  select(-c(whostandard)) %>%
  ungroup() 

aqli_gadm0_collapse_from_gadm2_finalized %>%
  readr::write_csv(str_c(ssd_location_collapsed_gadm0_data_path, "[finalizedApr2023]gadm0_aqli2021_vit.csv"))


# Note that the whostandard for annual average pm2.5 has been removed from all 3 levels, but for reference it can be found in the AQLI data dictionary. As of writing of this code, it was 5 micrograms per cubic meter.

#-----------
end_time_vit_data_pipeline <- Sys.time()
print(str_c("Total time taken: ", end_time_vit_data_pipeline - start_time,  " minutes?"))
```










# Remove waterbodies from AQLI datasets (both old colnames version and ViT colnames version)-------------------

```{r}

# load in the gadm2 processed files------------------------------
aqli_gadm2_collapse_master_finalized <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_non_geom.csv")
  
# change their colnames to AQLI internal col names that is expected by the collapsing code in the following steps after waterbodies adjustment to the gadm2 file
aqli_gadm2_collapse_master_finalized <- aqli_gadm2_collapse_master_finalized %>%
   dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) %>%
  rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard) %>%
    dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) 
  

#> Make the waterbodies file adjustment (removing waterbodies from AQLI files)-------------------------------------

# After processing the data and incorporating missing regions by resampling, we found out that
# the pipeline captures 58 waterbodies that include both lakes and seas. The reason why Caspian sea (or any water body) has a population #number is related to how our pipeline processes data for coastal areas. In our underlying landscan population raster, for regions near a water body, there will always be some pixels whose center lie on the water body (zoom into Lake Victoria and you'll notice that a lot of pixels are over both land and water). As a result, in the pipeline these "coastal" pixels get assigned to the corresponding polygon for that water body and as a result a population value is associated with it. That further leads to it also having a population weighted pollution value. This is something that in the future, we can work on addressing within the data pipeline itself. We for now, remove these waterbodies from the AQLI gadm2 processed files and recollapse to gadm1 and gadm0 both in the CSVs and the corresponding shapfiles.


# read in waterbodies file
waterbodies_aqli <- read_csv("./ar.2023.update.using.2021.pol.data/data/input/others/waterbodies_aqli.csv") 

waterbodies_aqli <- waterbodies_aqli %>%
  select(-type)

### Creating AQLI internal column name version of the CSVs=============================================

# create a version of old colnames gadm2 file that has waterbodies removed from it
aqli_gadm2_collapse_master_finalized_wat_adj_internal <- aqli_gadm2_collapse_master_finalized %>%
  anti_join(waterbodies_aqli, by = c("country" = "gadm0", "name_1" = "gadm1", "name_2" = "gadm2"))

# create a version of old colnames gadm1 file that has waterbodies removed from it
aqli_gadm1_collapse_master_finalized_wat_adj_internal <- aqli_gadm2_collapse_master_finalized_wat_adj_internal %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) %>%
  rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard)
  
# create a version of old colnames gadm0 file that has waterbodies removed from it  
aqli_gadm0_collapse_master_finalized_wat_adj_internal <- aqli_gadm2_collapse_master_finalized_wat_adj_internal %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
    dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) %>%
  rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard)


# write the above 3 internal AQLI column names style files to the relevant folder---------------
aqli_gadm2_collapse_master_finalized_wat_adj_internal %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/internal_aqli_colnames_csv/[june2023]gadm2_aqli_2021_post_waterbody_adj_finalized_internal.csv")

aqli_gadm1_collapse_master_finalized_wat_adj_internal %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/internal_aqli_colnames_csv/[june2023]gadm1_aqli_2021_post_waterbody_adj_finalized_internal.csv")

aqli_gadm0_collapse_master_finalized_wat_adj_internal %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/internal_aqli_colnames_csv/[june2023]gadm0_aqli_2021_post_waterbody_adj_finalized_internal.csv")



### Creating ViT colnames version of the CSVs===========================================

aqli_gadm2_collapse_master_finalized_wat_adj_external_vit <- aqli_gadm2_collapse_master_finalized_wat_adj_internal %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
    rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) 
  
  
aqli_gadm1_collapse_master_finalized_wat_adj_external_vit <- aqli_gadm1_collapse_master_finalized_wat_adj_internal %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
    rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) 

aqli_gadm0_collapse_master_finalized_wat_adj_external_vit <- aqli_gadm0_collapse_master_finalized_wat_adj_internal %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
   rename(name0 = country) %>%
  select(-c(whostandard)) 

 

# write the above 3 vit column name style files to the relevant folder---------------
aqli_gadm2_collapse_master_finalized_wat_adj_external_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm2_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")

aqli_gadm1_collapse_master_finalized_wat_adj_external_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm1_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")

aqli_gadm0_collapse_master_finalized_wat_adj_external_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm0_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")


```




# Politically Sensitive Regions (final step....or I thought so!)------------------

```{r eval=FALSE, include=FALSE}
#> read in the finalized files for 2023 shared with ViT (but partial AQLI colnames) in April, 2023 (if running the pipeline, from scratch - use the)----------

aqli_gadm2_collapse_master_finalized <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_non_geom.csv")
  

aqli_gadm1_collapse_from_gadm2_finalized <-
  read_csv("./ar.2023.update.using.2021.pol.data/data/output/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm1_non_geom.csv")

aqli_gadm0_collapse_from_gadm2_finalized <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm0_non_geom.csv")


#> read in the final files shared with ViT in April 2023 (with ViT colnames)----------------

vit_final_gadm2 <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm2_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")

vit_final_gadm1 <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm1_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")

vit_final_gadm0 <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shared_with_vit_colnames_csv/[june2023]gadm0_aqli_2021_post_waterbody_adj_finalized_external_vit.csv")

# removing objectid columns from each vit_final files for later "anti-joining".
vit_final_gadm2 <- vit_final_gadm2 %>%
  select(-objectid_gadm2)

vit_final_gadm1 <- vit_final_gadm1 %>%
  select(-objectid_gadm1)

vit_final_gadm0 <- vit_final_gadm0 %>%
  select(-objectid_gadm0)

### Executing steps from this (https://docs.google.com/spreadsheets/d/1ord7VYujSBuB_AuMJT5Kg9TQCyvhsvB4f0jsdnyI_Ss/edit#gid=1445767875)
### google sheet's Column D to get an India pov file.


```

# India POV files for all 3 gadm levels

```{r}

#> create a India point of view gadm2 file---------------------------

# National PM2.5 annual average standards for countries with world views (in micrograms per cubic meter): check if there are any updates to this.
natstan_india <- 40
natstan_pak <- 15
natstan_china <- 35
natstan_us <- 12


## 1.1.1 : move all name2 regions of Gilgit Baltistan [name1/pak] to Ladakh [name1/ind] and change their name0 to India

gilgit_baltistan_reassigned <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "Pakistan", name_1 == "Gilgit Baltistan") %>%
  mutate(name_1 = "Ladakh", country = "India", iso_alpha3 = "IND", natstandard = natstan_india)

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized %>%
  filter(!(country == "Pakistan" & name_1 %notin% "Gilgit Baltistan")) %>%
  bind_rows(gilgit_baltistan_reassigned)

# 1.1.2 collapse all (except Kargil) name2 regions of the name1 region of Ladakh (in India) into a single number and
#  assign that name2 region the following name: Leh (Ladakh). At this point, the name1 region of Ladakh
# has only 2 name2 regions: Kargil, Leh (Ladakh). 

leh_ladakh <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(country == "India", name_1 == "Ladakh", name_2 != "Kargil") %>%
  group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  dplyr::mutate(name_2 = "Leh (Ladakh)") %>%
  dplyr::select(objectid_gadm2:name_1, name_2, everything()) 

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!(country == "India" & name_1 == "Ladakh" & name_2 != "Kargil")) %>%
  bind_rows(leh_ladakh)
  
# 1.2.1 add all name2 regions of Azad Kashmir [name1/pak] to Jammu and Kashmir [name1/ind] and change their name0 to India.

azad_kashmir_reassigned <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(country == "Pakistan", name_1 == "Azad Kashmir") %>%
  mutate(country = "India", name_1 == "Jammu and Kashmir", iso_alpha3 = "IND", natstandard = natstan_india)

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!((country == "Pakistan") & (name_1 == "Azad Kashmir"))) %>%
  bind_rows(azad_kashmir_reassigned)

# 2.2 [name1/China] region of Hong Kong is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Hong Kong). All name2 regions of the newly created country Hong Kong are 
# now labelled as NA. (assumed that the newly created Hong Kong has the same natstandard as China )

hong_kong_reassigned <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(country == "China", name_1 == "Hong Kong") %>%
  mutate(country = "Hong Kong", name_1 = name_2, name_2 = NA, iso_alpha3 = "HKG")

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!((country == "China") & (name_1 == "Hong Kong"))) %>%
  bind_rows(hong_kong_reassigned)
 
  
# (2.3) [name1/China] region of Macau is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Macau). All name2 regions of the newly created country Macau are 
# now labelled as NA. Assumed that the newly created Macau has the same natstandard as China.

macau_reassigned <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(country == "China", name_1 == "Macau") %>%
  mutate(country = "Macau", name_1 = name_2, name_2 = NA, iso_alpha3 = "MAC")
 
aqli_gadm2_collapse_master_finalized_india_pov <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!((country == "China") & (name_1 == "Macau"))) %>%
  bind_rows(macau_reassigned)



# (4) After all of the above above changes to gadm2 fille, create a new objectid_gadm2 column, which will simply be the serial number, once done, the gadm2 India POV file is ready. Then, collapse the gadm2 India POV file to gadm1 and gadm0, to get the corresponding gadm1 India POVand gadm0 India POV. Finally, change the column names of all 3 levels to what's requested by ViT.

# assigining a serial number column to gadm2 india pov file
aqli_gadm2_collapse_master_finalized_india_pov <- aqli_gadm2_collapse_master_finalized_india_pov %>%
  mutate(objectid_gadm2 = row_number())


# collapsing gadm2 india pov to gadm0 india pov
aqli_gadm0_collapse_from_gadm2_finalized_india_pov <- aqli_gadm2_collapse_master_finalized_india_pov %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))


# collapsing gadm2 india pov to gadm1 india pov
aqli_gadm1_collapse_from_gadm2_finalized_india_pov <-  aqli_gadm2_collapse_master_finalized_india_pov %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))

## change names to as requested by ViT

# gadm2, rename: country, name_1, name_2 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm2_collapse_master_finalized_india_pov_vit <- aqli_gadm2_collapse_master_finalized_india_pov %>%
  rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm2)) 

# gadm1, rename: country, name_1 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm1_collapse_from_gadm2_finalized_india_pov_vit <- aqli_gadm1_collapse_from_gadm2_finalized_india_pov %>%
  rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm1)) 

# gadm0, rename country to name0 AND remove whostandard

aqli_gadm0_collapse_from_gadm2_finalized_india_pov_vit <- aqli_gadm0_collapse_from_gadm2_finalized_india_pov %>%
  rename(name0 = country) %>%
  select(-c(whostandard, objectid_gadm0)) 



#> export anti joined files for ViT for each level for India pov---------------

# gadm2
added_rows_gadm2_india_pov <- anti_join(aqli_gadm2_collapse_master_finalized_india_pov_vit, vit_final_gadm2, by = c("name0", "name1", "name2"))
deleted_rows_gadm2_india_pov <- anti_join(vit_final_gadm2, aqli_gadm2_collapse_master_finalized_india_pov_vit, by = c("name0", "name1", "name2"))

# gadm1
added_rows_gadm1_india_pov <- anti_join(aqli_gadm1_collapse_from_gadm2_finalized_india_pov_vit, vit_final_gadm1, by = c("name0", "name1"))
deleted_rows_gadm1_india_pov <- anti_join(vit_final_gadm1, aqli_gadm1_collapse_from_gadm2_finalized_india_pov_vit, by = c("name0", "name1"))

# gadm0
added_rows_gadm0_india_pov <- anti_join(aqli_gadm0_collapse_from_gadm2_finalized_india_pov_vit, vit_final_gadm0, by = c("name0"))
deleted_rows_gadm0_india_pov <- anti_join(vit_final_gadm0, aqli_gadm0_collapse_from_gadm2_finalized_india_pov_vit, by = c("name0")) # 0


## save the 6 files above to ssd (and then upload to box/drive > then add links here using this sheet as the base template: https://docs.google.com/spreadsheets/d/1ord7VYujSBuB_AuMJT5Kg9TQCyvhsvB4f0jsdnyI_Ss/edit#gid=1228164654)

# 1
added_rows_gadm2_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "added_rows_gadm2_india_pov.csv"))

# 2
added_rows_gadm1_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "added_rows_gadm1_india_pov.csv"))


# 3
added_rows_gadm0_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "added_rows_gadm0_india_pov.csv"))

# 4

deleted_rows_gadm2_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "deleted_rows_gadm2_india_pov.csv"))

# 5

deleted_rows_gadm1_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "deleted_rows_gadm1_india_pov.csv"))

# 6

deleted_rows_gadm0_india_pov %>% 
  write_csv(str_c(pov_files_folder_path, "india/additions_deletions/", "deleted_rows_gadm0_india_pov.csv"))

```


# China pov files for all 3 levels

```{r}

#>  (1.1) move all (except: Longding, Tirap, Changlang, Lohit, Namsai, Anjaw, Lower Dibang Valley, East Siang) name2 regions, of the [name1/ind] state of Arunachal Pradesh to China. Specifically, do the following to achieve this:

    # (1.1.1) Rename [name2/ind] regions of Dibang Valley, Upper Siang, West Siang (residing in the state of Andhra Pradesh [name1/Ind]) to Nyingtri [name2/china]. To all these region assign a name1: Xizang and a name0: China. Then collapse all name2 regions named Nyingtri into a single region named Nyingtri (taking population weighted pollution averages along the way).

# nyingtri in china    
nyingtri_china <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Xizang", name_2 == "Nyingtri")

# creating the new nyingtri
nyingtri_reorganized <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "India", name_1 == "Arunachal Pradesh", name_2 %in% c("Dibang Valley", 
                                                                       "Upper Siang", 
                                                                       "West Siang")) %>%
  mutate(name_2 = "Nyingtri", name_1 = "Xizang", country = "China", iso_alpha3 = "CHN", 
         natstandard = natstan_china) %>%
  bind_rows(nyingtri_china) %>%
  group_by(country) %>%
   dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
   mutate(name_1 = "Xizang", name_2 = "Nyingtri") %>%
   dplyr::select(objectid_gadm2:country, name_1, name_2, everything()) 
  

# Replace Nyingtri with the above mentioned regions in the gadm2 file
    
  aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized %>%
    filter(!((country == "India") & (name_1 == "Arunachal Pradesh") & (name_2 %in% c("Dibang Valley", 
                                                                               "Upper Siang", 
                                                                               "West Siang")))) %>%
    filter(!((country == "China") & (name_1 == "Xizang") & (name_2 == "Nyingtri"))) %>%
    bind_rows(nyingtri_reorganized)
  
#> (1.1.2) Rename [name2/ind] regions of Upper Subansiri, Kurung Kumey, Lower Subansiri, Papum Pare, East Kameng, West Kameng, Tawang (residing in the state of Arunachal Pradesh [name1/Ind]) to Shannan [name2/china]. To all these region assign a name1: Xizang and a name0: China. Then collapse all name2 regions named Shannan into a single region named Shannan (taking population weighted pollution averages along the way).

# shannan in china
shannan_china <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Xizang", name_2 == "Shannan")

# creating the new shannan
shannan_reorganized <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "India", name_1 == "Arunachal Pradesh", name_2 %in% c("Upper Subansiri", "Kurung Kumey", 
                                                                          "Lower Subansiri", "Papum Pare", 
                                                                          "East Kameng", "West Kameng", 
                                                                          "Tawang")) %>%
  mutate(name_2 = "Shannan", name_1 = "Xizang", country = "China", iso_alpha3 = "CHN", 
         natstandard = natstan_china) %>%
  bind_rows(shannan_china) %>% 
   group_by(country) %>%
   dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  dplyr::mutate(name_1 = "Xizang", name_2 = "Shannan") %>%
  dplyr::select(objectid_gadm2:name_1, name_2, everything()) 

# Replace Shannan with the above mentioned regions in the gadm2 file
    
  aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized_tmp %>%
    filter(!((country == "India") & (name_1 == "Arunachal Pradesh") & (name_2 %in% c("Upper Subansiri", "Kurung Kumey",
                                                                          "Lower Subansiri", "Papum Pare", 
                                                                          "East Kameng", "West Kameng", 
                                                                          "Tawang")))) %>%
      filter(!((country == "China") & (name_1 == "Xizang") & (name_2 == "Shannan"))) %>%
    bind_rows(shannan_reorganized)
    
#> (3) All name2 regions in the name0 region of Taiwan is collapsed to get population weighted pollution average numbers. Post that it's name0 name is changed to "China" and name1 and name2 names are changed to Taiwan.
  
taiwan_reorganized <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "Taiwan") %>%
  mutate(natstandard =  natstan_china) %>%
  group_by(country) %>%
   dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  mutate(iso_alpha3 = "CHN", country = "China", name_1 = "Taiwan", name_2 = "Taiwan", natstandard = natstan_china) %>%
   dplyr::select(objectid_gadm2:country, name_1, name_2, everything()) 


# adding the new name_1 taiwan after taking out the country taiwan

aqli_gadm2_collapse_master_finalized_china_pov <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!(country == "Taiwan")) %>%
  bind_rows(taiwan_reorganized)


#> (4) After all of the above above changes to gadm2 fille, create a new objectid_gadm2 column, which will simply be the serial number, once done, the gadm2 China POV file is ready. Then, collapse the gadm2 China POV file to gadm1 and gadm0, to get the corresponding gadm1 China POV and gadm0 China POV. Finally, change the column names of all 3 levels to what's requested by ViT.


# assigining a serial number column to gadm2 china pov file
aqli_gadm2_collapse_master_finalized_china_pov <- aqli_gadm2_collapse_master_finalized_china_pov %>%
  mutate(objectid_gadm2 = row_number())


# collapsing gadm2 china pov to gadm0 china pov
aqli_gadm0_collapse_from_gadm2_finalized_china_pov <- aqli_gadm2_collapse_master_finalized_china_pov %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))


# collapsing gadm2 china pov to gadm1 china pov
aqli_gadm1_collapse_from_gadm2_finalized_china_pov <-  aqli_gadm2_collapse_master_finalized_china_pov %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))

## change names to as requested by ViT

# gadm2, rename: country, name_1, name_2 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm2_collapse_master_finalized_china_pov_vit <- aqli_gadm2_collapse_master_finalized_china_pov %>%
  rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm2)) 

# gadm1, rename: country, name_1 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm1_collapse_from_gadm2_finalized_china_pov_vit <- aqli_gadm1_collapse_from_gadm2_finalized_china_pov %>%
  rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm1)) 

# gadm0, rename country to name0 AND remove whostandard

aqli_gadm0_collapse_from_gadm2_finalized_china_pov_vit <- aqli_gadm0_collapse_from_gadm2_finalized_china_pov %>%
  rename(name0 = country) %>%
  select(-c(whostandard, objectid_gadm0)) 

#> export anti joined files for ViT for each level for China pov---------------

# gadm2
added_rows_gadm2_china_pov <- anti_join(aqli_gadm2_collapse_master_finalized_china_pov_vit, vit_final_gadm2, by = c("name0", "name1", "name2"))
deleted_rows_gadm2_china_pov <- anti_join(vit_final_gadm2, aqli_gadm2_collapse_master_finalized_china_pov_vit, by = c("name0", "name1", "name2"))

# gadm1
added_rows_gadm1_china_pov <- anti_join(aqli_gadm1_collapse_from_gadm2_finalized_china_pov_vit, vit_final_gadm1, by = c("name0", "name1"))
deleted_rows_gadm1_china_pov <- anti_join(vit_final_gadm1, aqli_gadm1_collapse_from_gadm2_finalized_china_pov_vit, by = c("name0", "name1"))

# gadm0
added_rows_gadm0_china_pov <- anti_join(aqli_gadm0_collapse_from_gadm2_finalized_china_pov_vit, vit_final_gadm0, by = c("name0"))
deleted_rows_gadm0_china_pov <- anti_join(vit_final_gadm0, aqli_gadm0_collapse_from_gadm2_finalized_china_pov_vit, by = c("name0")) # 0


## save the 6 files above to ssd (and then upload to box/drive > then add links here using this sheet as the base template: https://docs.google.com/spreadsheets/d/1ord7VYujSBuB_AuMJT5Kg9TQCyvhsvB4f0jsdnyI_Ss/edit#gid=1228164654 )

# 1
added_rows_gadm2_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "added_rows_gadm2_china_pov.csv"))

# 2

added_rows_gadm1_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "added_rows_gadm1_china_pov.csv"))
 
# 3

added_rows_gadm0_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "added_rows_gadm0_china_pov.csv"))
 
# 4

deleted_rows_gadm2_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "deleted_rows_gadm2_china_pov.csv"))
 
# 5

deleted_rows_gadm1_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "deleted_rows_gadm1_china_pov.csv"))

 
# 6

deleted_rows_gadm0_china_pov %>%
 write_csv(str_c(pov_files_folder_path, "china/additions_deletions/", "deleted_rows_gadm0_china_pov.csv"))


```

# Pakistan pov files for all 3 levels

```{r}

# (1.1) [name1/China] region of Hong Kong is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Hong Kong). All name2 regions of the newly created country Hong Kong are
# now labelled as NA. (assumed that the newly created Hong Kong has the same natstandard as China )

hong_kong_reassigned <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Hong Kong") %>%
  mutate(country = "Hong Kong", name_1 = name_2, name_2 = NA, iso_alpha3 = "HKG")

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized %>%
  filter(!((country == "China") & (name_1 == "Hong Kong"))) %>%
  bind_rows(hong_kong_reassigned)
 
  
# (1.2) [name1/China] region of Macau is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Macau). All name2 regions of the newly created country Macau are 
# now labelled as NA. Assumed that the newly created Macau has the same natstandard as China.

macau_reassigned <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Macau") %>%
  mutate(country = "Macau", name_1 = name_2, name_2 = NA, iso_alpha3 = "MAC")
 
aqli_gadm2_collapse_master_finalized_pakistan_pov <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!((country == "China") & (name_1 == "Macau"))) %>%
  bind_rows(macau_reassigned)

#> (2) After all of the above above changes to gadm2 fille, create a new objectid_gadm2 column, which will simply be the serial number, once done, the gadm2 Pakistan POV file is ready. Then, collapse the gadm2 Pakistan POV file to gadm1 and gadm0, to get the corresponding gadm1 Pakistan POV and gadm0 Pakistan POV (in doing so also change the column names to what's requested by ViT). Finally, change the column names of all 3 levels to what's requested by ViT.


# assigining a serial number column to gadm2 pakistan pov file
aqli_gadm2_collapse_master_finalized_pakistan_pov <- aqli_gadm2_collapse_master_finalized_pakistan_pov %>%
  mutate(objectid_gadm2 = row_number())


# collapsing gadm2 pakistan pov to gadm0 pakistan pov
aqli_gadm0_collapse_from_gadm2_finalized_pakistan_pov <- aqli_gadm2_collapse_master_finalized_pakistan_pov %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))


# collapsing gadm2 pakistan pov to gadm1 pakistan pov
aqli_gadm1_collapse_from_gadm2_finalized_pakistan_pov <-  aqli_gadm2_collapse_master_finalized_pakistan_pov %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))

## change names to as requested by ViT

# gadm2, rename: country, name_1, name_2 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm2_collapse_master_finalized_pakistan_pov_vit <- aqli_gadm2_collapse_master_finalized_pakistan_pov %>%
  rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm2)) 

# gadm1, rename: country, name_1 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm1_collapse_from_gadm2_finalized_pakistan_pov_vit <- aqli_gadm1_collapse_from_gadm2_finalized_pakistan_pov %>%
  rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm1)) 

# gadm0, rename country to name0 AND remove whostandard

aqli_gadm0_collapse_from_gadm2_finalized_pakistan_pov_vit <- aqli_gadm0_collapse_from_gadm2_finalized_pakistan_pov %>%
  rename(name0 = country) %>%
  select(-c(whostandard, objectid_gadm0)) 


#> export anti joined files for ViT for each level for Pakistan pov---------------

# gadm2
added_rows_gadm2_pakistan_pov <- anti_join(aqli_gadm2_collapse_master_finalized_pakistan_pov_vit, vit_final_gadm2, by = c("name0", "name1", "name2"))
deleted_rows_gadm2_pakistan_pov <- anti_join(vit_final_gadm2, aqli_gadm2_collapse_master_finalized_pakistan_pov_vit, by = c("name0", "name1", "name2"))

# gadm1
added_rows_gadm1_pakistan_pov <- anti_join(aqli_gadm1_collapse_from_gadm2_finalized_pakistan_pov_vit, vit_final_gadm1, by = c("name0", "name1"))
deleted_rows_gadm1_pakistan_pov <- anti_join(vit_final_gadm1, aqli_gadm1_collapse_from_gadm2_finalized_pakistan_pov_vit, by = c("name0", "name1"))

# gadm0
added_rows_gadm0_pakistan_pov <- anti_join(aqli_gadm0_collapse_from_gadm2_finalized_pakistan_pov_vit, vit_final_gadm0, by = c("name0"))
deleted_rows_gadm0_pakistan_pov <- anti_join(vit_final_gadm0, aqli_gadm0_collapse_from_gadm2_finalized_pakistan_pov_vit, by = c("name0")) 

## save the 6 files above to ssd (and then upload to box/drive > then add links here using this sheet as the base template: https://docs.google.com/spreadsheets/d/1ord7VYujSBuB_AuMJT5Kg9TQCyvhsvB4f0jsdnyI_Ss/edit#gid=1228164654 )

# 1
added_rows_gadm2_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "added_rows_gadm2_pakistan_pov.csv"))

# 2
added_rows_gadm1_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "added_rows_gadm1_pakistan_pov.csv"))

# 3
added_rows_gadm0_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "added_rows_gadm0_pakistan_pov.csv"))

# 4
deleted_rows_gadm2_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "deleted_rows_gadm2_pakistan_pov.csv"))

# 5
deleted_rows_gadm1_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "deleted_rows_gadm1_pakistan_pov.csv"))


# 6
deleted_rows_gadm0_pakistan_pov %>%
 write_csv(str_c(pov_files_folder_path, "pakistan/additions_deletions/", "deleted_rows_gadm0_pakistan_pov.csv"))




```

# US/GLobal/de-facto view pov files for all 3 levels (as of May 2023, this view is the same as Pakistan view)

```{r}


# (1.1) [name1/China] region of Hong Kong is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Hong Kong). All name2 regions of the newly created country Hong Kong are
# now labelled as NA. (assumed that the newly created Hong Kong has the same natstandard as China )

hong_kong_reassigned <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Hong Kong") %>%
  mutate(country = "Hong Kong", name_1 = name_2, name_2 = NA, iso_alpha3 = "HKG")

aqli_gadm2_collapse_master_finalized_tmp <- aqli_gadm2_collapse_master_finalized %>%
  filter(!((country == "China") & (name_1 == "Hong Kong"))) %>%
  bind_rows(hong_kong_reassigned)
 
  
# (1.2) [name1/China] region of Macau is removed and added as a new country (name0) and all its name2 regions
# now become name1 regions of the new country (Macau). All name2 regions of the newly created country Macau are 
# now labelled as NA. Assumed that the newly created Macau has the same natstandard as China.

macau_reassigned <- aqli_gadm2_collapse_master_finalized %>%
  filter(country == "China", name_1 == "Macau") %>%
  mutate(country = "Macau", name_1 = name_2, name_2 = NA, iso_alpha3 = "MAC")
 
aqli_gadm2_collapse_master_finalized_rotw_pov <- aqli_gadm2_collapse_master_finalized_tmp %>%
  filter(!((country == "China") & (name_1 == "Macau"))) %>%
  bind_rows(macau_reassigned)

#> (2) After all of the above above changes to gadm2 fille, create a new objectid_gadm2 column, which will simply be the serial number, once done, the gadm2 US/Rest of the Globe POV file is ready (rotw: rest of the world). Then, collapse the gadm2 US/Rest of the Globe POV file to gadm1 and gadm0, to get the corresponding gadm1 US/Rest of the Globe POV and gadm0 US/Rest of the Globe POV. Finally, change the column names of all 3 levels to what's requested by ViT.


# assigining a serial number column to gadm2 rotw (rest of the world) pov file
aqli_gadm2_collapse_master_finalized_rotw_pov <- aqli_gadm2_collapse_master_finalized_rotw_pov %>%
  mutate(objectid_gadm2 = row_number())


# collapsing gadm2 rotw pov to gadm0 rotw pov
aqli_gadm0_collapse_from_gadm2_finalized_rotw_pov <- aqli_gadm2_collapse_master_finalized_rotw_pov %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))


# collapsing gadm2 rotw pov to gadm1 rotw pov
aqli_gadm1_collapse_from_gadm2_finalized_rotw_pov <-  aqli_gadm2_collapse_master_finalized_rotw_pov %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard))

## change names to as requested by ViT

# gadm2, rename: country, name_1, name_2 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm2_collapse_master_finalized_rotw_pov_vit <- aqli_gadm2_collapse_master_finalized_rotw_pov %>%
  rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm2)) 

# gadm1, rename: country, name_1 AND remove iso_alpha3, natstandard, whostandard

aqli_gadm1_collapse_from_gadm2_finalized_rotw_pov_vit <- aqli_gadm1_collapse_from_gadm2_finalized_rotw_pov %>%
  rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard, objectid_gadm1)) 

# gadm0, rename country to name0 AND remove whostandard

aqli_gadm0_collapse_from_gadm2_finalized_rotw_pov_vit <- aqli_gadm0_collapse_from_gadm2_finalized_rotw_pov %>%
  rename(name0 = country) %>%
  select(-c(whostandard, objectid_gadm0)) 


#> export anti joined files for ViT for each level for rotw pov---------------

# gadm2
added_rows_gadm2_rotw_pov <- anti_join(aqli_gadm2_collapse_master_finalized_rotw_pov_vit, vit_final_gadm2, by = c("name0", "name1", "name2"))
deleted_rows_gadm2_rotw_pov <- anti_join(vit_final_gadm2, aqli_gadm2_collapse_master_finalized_rotw_pov_vit, by = c("name0", "name1", "name2"))

# gadm1
added_rows_gadm1_rotw_pov <- anti_join(aqli_gadm1_collapse_from_gadm2_finalized_rotw_pov_vit, vit_final_gadm1, by = c("name0", "name1"))
deleted_rows_gadm1_rotw_pov <- anti_join(vit_final_gadm1, aqli_gadm1_collapse_from_gadm2_finalized_rotw_pov_vit, by = c("name0", "name1"))

# gadm0
added_rows_gadm0_rotw_pov <- anti_join(aqli_gadm0_collapse_from_gadm2_finalized_rotw_pov_vit, vit_final_gadm0, by = c("name0"))
deleted_rows_gadm0_rotw_pov <- anti_join(vit_final_gadm0, aqli_gadm0_collapse_from_gadm2_finalized_rotw_pov_vit, by = c("name0")) 

## save the 6 files above to ssd (and then upload to box/drive > then add links here using this sheet as the base template: https://docs.google.com/spreadsheets/d/1ord7VYujSBuB_AuMJT5Kg9TQCyvhsvB4f0jsdnyI_Ss/edit#gid=1228164654 )

# 1
added_rows_gadm2_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "added_rows_gadm2_rotw_pov.csv"))

# 2
added_rows_gadm1_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "added_rows_gadm1_rotw_pov.csv"))

# 3

added_rows_gadm0_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "added_rows_gadm0_rotw_pov.csv"))


# 4
deleted_rows_gadm2_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "deleted_rows_gadm2_rotw_pov.csv"))

# 5

deleted_rows_gadm1_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "deleted_rows_gadm1_rotw_pov.csv"))

# 6

deleted_rows_gadm0_rotw_pov %>%
 write_csv(str_c(pov_files_folder_path, "rotw/additions_deletions/", "deleted_rows_gadm0_rotw_pov.csv"))



```




# Sharing our shapefiles with ViT

```{r}
# reading in the finalized gadm2 csv and filtering the colormap shapefile to only contain those ids that are present in the gadm2 csv
# (if already read in above, in the pov bit or earlier, don't read it again). In this case, I have already read in the files from the 
# first chunk of the pov files processing. These files are in ViT naming format.

# only keep those objectids in gadm2 that are present in the CSV
vit_final_gadm2_objectids <- vit_final_gadm2$objectid_gadm2

# make column name changes to the shapefile and bring it in the format as preferred by ViT
gadm2_shapefile_vit_valid_final <- colormap %>%
  rename(name0 = NAME_0, 
         name1 = NAME_1, 
         name2 = NAME_2,
         isoalp3 = iso_alpha3,
         obidgadm2 = objectid) %>%
  select(obidgadm2, isoalp3, name0, name1, name2, geometry)

# filter for the above selected objectids
gadm2_shapefile_vit_valid_final_subset <- gadm2_shapefile_vit_valid_final %>%
  filter(obidgadm2 %in% vit_final_gadm2_objectids)

# write gadm2 shapefile for ViT
gadm2_shapefile_vit_valid_final_subset %>%
  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/aqli_gadm2_intermed_june2023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")

# create gadm1 and gadm0 shapefile in QGIS (by using the dissolve feature under Vector > Geoprocessing)

# read all 3 gadm level files saved and make final adjustments before exporting it to share with ViT
gadm2_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/aqli_gadm2_intermed_june2023.shp")

gadm1_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/aqli_gadm1_intermed_june2023.shp")

gadm0_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/aqli_gadm0_intermed_june2023.shp")


# finalize gadm2 shapefile for ViT
gadm2_shapefile_final_qgis <- gadm2_shapefile_intermed_qgis %>%
  select(obidgadm2, name0, name1, name2, geometry) %>%
  arrange(obidgadm2)

# finalize gadm1 shapefile for ViT
gadm1_shapefile_final_qgis <- gadm1_shapefile_intermed_qgis %>%
  select(-c(obidgadm2, isoalp3, name2)) %>%
  arrange(name0, name1) %>%
  mutate(obidgadm1 = row_number()) %>%
  select(obidgadm1, name0,  name1, geometry) 

# finalize gadm0 shapefile for ViT

india_polygon <- gadm0_shapefile_intermed_qgis %>% 
  filter(name0 == "India") %>%
  st_make_valid() %>%
  group_by(name0) %>%
  summarise() %>%
  mutate(isoalp3 = "IND") %>%
  select(isoalp3, name0, geometry)

gadm0_shapefile_final_qgis <- gadm0_shapefile_intermed_qgis %>%
  select(-c(obidgadm2, name1, name2)) %>%
  filter(!(name0 == "India")) %>%
  bind_rows(india_polygon) %>%
  arrange(name0) %>%
  mutate(obidgadm0 = row_number()) %>%
  select(obidgadm0, isoalp3, name0, geometry)

gadm0_shapefile_final_qgis <- gadm0_shapefile_final_qgis %>%
  st_as_sf()


#> write finalized shapefiles to be shared with ViT

# gadm2
gadm2_shapefile_final_qgis %>%  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/gadm2/aqli_gadm2_final_june2023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")
 
 
 # gadm1

gadm1_shapefile_final_qgis %>%
  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/gadm1/aqli_gadm1_final_june2023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")
 
 
 # gadm0

gadm0_shapefile_final_qgis %>%
  sf::st_write("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/shapefiles_final/gadm0/aqli_gadm0_final_june2023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")
```










# readding the missing regions so that it can be shown as NA on the map and updating the natstandards of a couple countries to NA as instead of keeping the "historical" AQLI standards for a couple countries for which NAAQS do not exist as per the UNEP 2021 report, we decided to report them as NA, this additional adjustment will be made for the list of countries listed below.-----------------------------

```{r}

# load in the AQLI gadm2 waterbodies objectids (pre-saved for the current dataset)
objids_waterbodies_gadm2 <- read_csv("./ar.2023.update.using.2021.pol.data/data/input/others/waterbodies_objectids_gadm2.csv")  #58
objids_waterbodies_gadm2 <- objids_waterbodies_gadm2 %>%  
  filter(objectid_gadm2  != 43636)                           # 57

# load in AQLI internal column names latest gadm2 dataset (waterbodies removed) and add Bear lake (which is not actually a lake)
gadm2_aqli_2021_without_missing_data_regions <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_post_waterbodies_adj_june2023/internal_aqli_colnames_csv/[june2023]gadm2_aqli_2021_post_waterbody_adj_finalized_internal.csv")


#> add back Bear Lake (the hole in Idaho, which I previously thought was a lake, but is actually a county of the same name containing
#> the lake of the same name: funny!)--------------------------------------------------------------------------------------------------

# load in the gadm2 processed files (with waterbodies)
tmp_gadm2_with_waterbodies <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/[missingAndNAPopRegionsIncorpButViTcolNameChangesPartiallyIncorp]master_global_allyears_gadm2_non_geom.csv")

# change back to AQLI internal column name structure
tmp_gadm2_with_waterbodies <- tmp_gadm2_with_waterbodies %>%
  dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) 
  
# bear lake
bear_lake <- tmp_gadm2_with_waterbodies %>%
  filter(name_2  == "Bear Lake") %>%
    rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard)

# add back to the main gadm2 dataset
gadm2_aqli_2021_without_missing_data_regions <- gadm2_aqli_2021_without_missing_data_regions %>%
  bind_rows(bear_lake) %>%
  arrange(objectid_gadm2)
  













#> national standards updated read in (if updated are already present above, don't update again)

# reading in the national standards file (jan 2023 uodate file)
national_standards_pm2.5 <- readr::read_csv(stringr::str_c(national_standards_pm2.5_jan_2023_location, national_standards_pm2.5_jan_2023_file_name, sep = ""))


# keeping and renaming relevant columns
national_standards_pm2.5 <- national_standards_pm2.5 %>%
  dplyr::select(country, natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1) %>%
  dplyr::rename(natstandard_updated = natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1)


# reading in the national standards file (june 2023 uodate file)
national_standards_pm2.5_june2023 <- readr::read_csv(stringr::str_c(national_standards_pm2.5_jan_2023_location, national_standards_pm2.5_june_2023_file_name, sep = ""))


# keeping and renaming relevant columns in national standards june 2023 file
national_standards_pm2.5_june2023 <- national_standards_pm2.5_june2023 %>%
  dplyr::select(country, natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1) %>%
  dplyr::rename(natstandard_updated = natstandard_pm2.5_new_2023_report_micr_grm_cubic_meter_op1)


# joining old and new nat standard file
old_new_nat_list_join <- national_standards_pm2.5 %>%
  left_join(national_standards_pm2.5_june2023, by = "country")

# filtering only those countries whose nat standards have been updated to NA in the June 2023 second round of natstandrd update
country_natstan_upd_na <- old_new_nat_list_join %>%
  mutate(updated_country = ifelse(natstandard_updated.x != "No national standard" & natstandard_updated.y == "No national standard", 1, 0)) %>%
  filter(updated_country == 1) %>%
  select(country) %>%
  unlist() %>%
  as.vector()

#------------------------------------------------------------------------------------------------------

objids_waterbodies_gadm2 <-  objids_waterbodies_gadm2 %>%
  unlist() %>%
  as.vector()

# removing waterbodies from colormap
colormap_sans_waterbodies <- colormap %>%
  filter(objectid %notin% objids_waterbodies_gadm2)

# gadm 2 missing data regions complete list
gadm2_regions_missing_data <- colormap_sans_waterbodies %>%
  anti_join(gadm2_aqli_2021_without_missing_data_regions, by = c("objectid" = "objectid_gadm2")) %>%
  st_drop_geometry()

# add national standards to missing data regions list
gadm2_regions_missing_data <- gadm2_regions_missing_data %>%
  left_join(national_standards_pm2.5_june2023, by = c("NAME_0" = "country")) %>%
  rename(natstandard = natstandard_updated, 
         country = NAME_0, 
         name_1 = NAME_1, 
         name_2 = NAME_2, 
         objectid_gadm2 = objectid) %>%
  mutate(whostandard = 5, 
         population = NA, 
         natstandard = ifelse(natstandard == "No national standard", NA, natstandard)) %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, name_2, population, whostandard, natstandard)

# changing the national standards column to numeric
gadm2_regions_missing_data$natstandard <- as.numeric(gadm2_regions_missing_data$natstandard)

#> internal AQLI CSVs----------------------------------------

# GADM2: add the missing data regions to the gadm2 (waterbodies removed and also remove any zero population regions) data to create the final gadm2 data and incorporate countries, whose national standards have been NA'd
gadm2_aqli_2021_with_missing_data_regions <- gadm2_regions_missing_data %>%
  bind_rows(gadm2_aqli_2021_without_missing_data_regions) %>%
  arrange(objectid_gadm2) %>%
  mutate(natstandard = ifelse(country %in% country_natstan_upd_na, NA, natstandard)) %>%
  dplyr::mutate(across(matches("llpp_nat"), ~ifelse(is.na(natstandard), NA, .x)))

# update Thailand national standard to 15 micrograms per cubic meter and replace the thailand rows in gadm2 with this updated dataset
thailand_gadm2 <- gadm2_aqli_2021_with_missing_data_regions %>%
  filter(country == "Thailand") %>%
  mutate(natstandard = 15) %>%
  dplyr::select(-(starts_with("llpp_nat_"))) %>%
  dplyr::mutate(across(starts_with("pm"), (~round((.x - natstandard)*aqli_lyl_constant, 2)), .names = "llpp_nat_{col}")) %>%
  dplyr::mutate(across(starts_with("llpp_nat_"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat_"), ~ifelse(natstandard == 0, NA, .x))) %>%
    dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp_nat_")) 

# add back Thailand new updated dataset
gadm2_aqli_2021_with_missing_data_regions <- gadm2_aqli_2021_with_missing_data_regions %>%
  filter(country != "Thailand") %>%
  bind_rows(thailand_gadm2) %>%
  arrange(objectid_gadm2)


# I  am here

#> -------------------------------------------

# reate the final gadm1 file from the above missing data incorporated waterbodies removed csv
gadm1_aqli_2021_with_missing_data_regions <- gadm2_aqli_2021_with_missing_data_regions %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
  dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) %>%
  rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard) %>%
  dplyr::mutate(across(matches("pm|llpp"), ~ifelse(population == 0, NA, .x))) %>%
  dplyr::mutate(population = ifelse(population == 0, NA, population))
  
# create a version of old colnames gadm0 file that has waterbodies removed from it  
gadm0_aqli_2021_with_missing_data_regions <- gadm2_aqli_2021_with_missing_data_regions %>%
  dplyr::group_by(country) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  dplyr::ungroup() %>%
  select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm0 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 2)), .names = "{col}")) %>%
   dplyr::rename_with(~str_replace(.x, "llpp_", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(natstandard = ifelse(natstandard == 0, NA, natstandard)) %>%
    dplyr::rename_with(~str_replace(.x, "who", "llpp_who_"), dplyr::contains("who")) %>%
  dplyr::rename_with(~str_replace(.x, "nat", "llpp_nat_"), dplyr::contains("nat")) %>%
  rename(whostandard = llpp_who_standard,
         natstandard = llpp_nat_standard) %>%
  dplyr::mutate(across(matches("pm|llpp"), ~ifelse(population == 0, NA, .x))) %>%
  dplyr::mutate(population = ifelse(population == 0, NA, population))



# write the above 3 internal AQLI column names style files to the relevant folder---------------
gadm2_aqli_2021_with_missing_data_regions %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/internal_aqli_colnames_csv/[june302023]gadm2_aqli_2021_internal_col_names.csv")

  gadm1_aqli_2021_with_missing_data_regions %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/internal_aqli_colnames_csv/[june302023]gadm1_aqli_2021_internal_col_names.csv")

  
gadm0_aqli_2021_with_missing_data_regions %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/internal_aqli_colnames_csv/[june302023]gadm0_aqli_2021_internal_col_names.csv")





### Creating ViT colnames version of the CSVs===========================================

gadm2_aqli_2021_with_missing_data_regions_vit <- gadm2_aqli_2021_with_missing_data_regions %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
    rename(name0 = country, name1 = name_1, name2 = name_2) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) 
  
  
gadm1_aqli_2021_with_missing_data_regions_vit <- gadm1_aqli_2021_with_missing_data_regions %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
    rename(name0 = country, name1 = name_1) %>%
  select(-c(iso_alpha3, natstandard, whostandard)) 

gadm0_aqli_2021_with_missing_data_regions_vit <- gadm0_aqli_2021_with_missing_data_regions %>%
  dplyr::rename_with(~str_replace(.x, "llpp_who_", "who"), dplyr::contains("llpp_who_")) %>%
  dplyr::rename_with(~str_replace(.x, "llpp_nat_", "nat"), dplyr::contains("llpp_nat_")) %>%
   rename(name0 = country) %>%
  select(-c(whostandard)) 



# write the above 3 vit column name style files to the relevant folder---------------
gadm2_aqli_2021_with_missing_data_regions_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shared_with_vit_colnames_csv/[june302023]gadm2_aqli_2021_vit.csv")

  gadm1_aqli_2021_with_missing_data_regions_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shared_with_vit_colnames_csv/[june302023]gadm1_aqli_2021_vit.csv")

  
gadm0_aqli_2021_with_missing_data_regions_vit %>%
  write_csv("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shared_with_vit_colnames_csv/[june302023]gadm0_aqli_2021_vit.csv")





#> rewriting shapefiles---------------------------------------------------------------------------



# make column name changes to the shapefile and bring it in the format as preferred by ViT
gadm2_shapefile_vit_valid_final_june302023 <- colormap_sans_waterbodies %>%
  rename(name0 = NAME_0, 
         name1 = NAME_1, 
         name2 = NAME_2,
         isoalp3 = iso_alpha3,
         obidgadm2 = objectid) %>%
  select(obidgadm2, isoalp3, name0, name1, name2, geometry)

# write gadm2 shapefile for ViT
gadm2_shapefile_vit_valid_final_june302023 %>%
  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/aqli_gadm2_intermed_june302023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")

# create gadm1 and gadm0 shapefile in QGIS (by using the dissolve feature under Vector > Geoprocessing)

# read all 3 gadm level files saved and make final adjustments before exporting it to share with ViT
gadm2_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/aqli_gadm2_intermed_june302023.shp")

gadm1_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/aqli_gadm1_intermed_june302023.shp")

gadm0_shapefile_intermed_qgis <- sf::st_read("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/aqli_gadm0_intermed_june302023.shp")


# finalize gadm2 shapefile for ViT
gadm2_shapefile_final_qgis <- gadm2_shapefile_intermed_qgis %>%
  select(obidgadm2, name0, name1, name2, geometry) %>%
  arrange(obidgadm2)

# finalize gadm1 shapefile for ViT
gadm1_shapefile_final_qgis <- gadm1_shapefile_intermed_qgis %>%
  select(-c(obidgadm2, isoalp3, name2)) %>%
  arrange(name0, name1) %>%
  mutate(obidgadm1 = row_number()) %>%
  select(obidgadm1, name0,  name1, geometry) 

# finalize gadm0 shapefile for ViT

india_polygon <- gadm0_shapefile_intermed_qgis %>% 
  filter(name0 == "India") %>%
  st_make_valid() %>%
  group_by(name0) %>%
  summarise() %>%
  mutate(isoalp3 = "IND") %>%
  select(isoalp3, name0, geometry)

gadm0_shapefile_final_qgis <- gadm0_shapefile_intermed_qgis %>%
  select(-c(obidgadm2, name1, name2)) %>%
  filter(!(name0 == "India")) %>%
  bind_rows(india_polygon) %>%
  arrange(name0) %>%
  mutate(obidgadm0 = row_number()) %>%
  select(obidgadm0, isoalp3, name0, geometry)

gadm0_shapefile_final_qgis <- gadm0_shapefile_final_qgis %>%
  st_as_sf()


#> write finalized shapefiles to be shared with ViT

# gadm2
gadm2_shapefile_final_qgis %>%  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/gadm2/aqli_gadm2_final_june302023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")
 
 
 # gadm1

gadm1_shapefile_final_qgis %>%
  sf::write_sf("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/gadm1/aqli_gadm1_final_june302023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")
 
 
 # gadm0

gadm0_shapefile_final_qgis %>%
  sf::st_write("./ar.2023.update.using.2021.pol.data/data/output_post_missing_data_incorp_and_nat_stan_upd_endJune_earlyJuly2023/shapefiles_final/gadm0/aqli_gadm0_final_june302023.shp", driver = "ESRI Shapefile", layer_options = "ENCODING=UTF-8")







```











#> Main pipeline ends here---------------------------------------------------------------------------------------------------------







#> Sanity checks and other independent tests----------------------------------------------------------------------------------------

#> Capturing the missing pollution regions and the NA population regions that were left out in the process above because there tiny size.---------------------------------------

#Specifically, in the AQLI 2023 update, there were 153 missing pollution regions, of which 70 were expected to be missing because they were either below 54.995 S or above 67.995 N. Remaining 83 regions were probably extremely small in size (there area being less than the higest available resolution, i.e. 0.01 degree^2, which is ~1km^2), such that when the shapefile was rasterized, these region polygons were so small that no pixel's center lay in them post rasterizing and hence they did not show up in the final list. The rasterizing algorithm works by assigning the pixel in the rasterized version the unique id of the underlying polygon it belongs to, but for that it uses pixel's center to see which underlying polygon that pixel belongs to. To resolve this, for these 153 missing regions we will be rasterizing the shapefile to a resolution of 0.001 degree^2, so that we can capture them. In doing so, it's important to know that interpolating population to higher resoltions doesn't work, so instead we have to interpolate population densities.

# Apart from this there were 97 regions that were captured in the rasterization process, but there population was 0/NA. A similar process would be applied to them.

# Hopefully, once this process is complete all of the regions would be captured. If not, you can try resampling to an even higher resolution, e.g. 0.0001 (10mx10m). But, that would be extremely memory intensive.

# NA pop regions capture
```{r na_pop_regions_capture, eval=FALSE, include=FALSE}

#> create a vector of objectids where population is NA

# read in the gadm level 2 file
gadm2_aqli_2021 <- readr::read_csv("./ar.2023.update.using.2021.pol.data/data/output_vit/gadm2_aqli2021_vit.csv")

# NA pop regions
objectid_gadm2_na_pop <- gadm2_aqli_2021 %>%
  filter(is.na(population)) %>%
  pull(objectid_gadm2) %>%
  as.vector()

# processing all NA pop regions and outputting a single dataset for all regions containing pollution info for all years
na_pop_regions_processed <- regional_summary(colormap, pol_data_location, pop_raw_landscan_crop_pol, 0.001,objectid_gadm2_na_pop, 1998, 0.00833333)

# calculating area of the 97 na population regions (sanity check)
na_pop_regions_colormap <- colormap %>%
  filter(objectid %in% objectid_gadm2_na_pop)

# calculating area for the above regions, after transforming to crs 4326
na_pop_regions_colormap <- st_transform(na_pop_regions_colormap, 4326)
na_pop_regions_colormap <- st_make_valid(na_pop_regions_colormap)

# creating a new column that will measure area in square kilometers
na_pop_regions_colormap$area <- as.numeric(st_area(na_pop_regions_colormap)/(10^6))

# creating a new column that displays area without units
na_pop_regions_colormap <- na_pop_regions_colormap %>%
  mutate(area_sans_units = as.numeric(area)) %>%
  st_drop_geometry()

na_pop_regions_colormap %>%
  filter(area_sans_units > 500) %>%
  View()

```








# missing regions capture
```{r missing_regions_capture, eval=FALSE, include=FALSE}
#> Applying a similar
 
# area calculations example
# c_russia <- colormap %>% filter(NAME_0 == "Russia")
# c_russia <- st_transform(c_russia, 4326)
# c_russia <- c_russia %>% st_make_valid()
# c_russia$area <- st_area(c_russia)/(10^6)

# read in 2021 processed aqli gadm2 data
aqli_2021_gadm2_test <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_vit/gadm2_aqli2021_vit.csv")

# get indices for missing areas
missing_ids_index <- colormap$objectid %notin% aqli_2021_gadm2_test$objectid_gadm2

# missing areas
missing_areas <- colormap[missing_ids_index, ]

# calculating areas for missing areas and filetering areas whose area is less than or equal to  a threshold
missing_areas <- st_transform(missing_areas, 4326)
missing_areas <- st_make_valid(missing_areas)

# creating a new column called area
missing_areas$area <- as.numeric(st_area(missing_areas)/(10^6))

# create a non-geom version of the dataset
missing_areas_drop_geom <- missing_areas %>%
  mutate(area_sans_units = as.numeric(area)) %>%
  st_drop_geometry()

# viewing the top 50 largest missing areas
missing_areas_drop_geom %>%
  slice_max(area_sans_units > 50) %>% View() 

# regions that we expect to be missing and filtering them out of the above list
missing_regions_exp_to_be_missing <- readxl::read_xlsx("C:/Users/Aarsh/Desktop/others/part-1_expectToBeMissing.xlsx")

# regions we don't expect to be missing according to the csv
missing_regions_dont_expect_missing <- missing_areas_drop_geom %>%
  filter(NAME_0 %notin% missing_regions_exp_to_be_missing$NAME_0 & 
        NAME_1 %notin% missing_regions_exp_to_be_missing$NAME_1 &
        NAME_2 %notin% missing_regions_exp_to_be_missing$NAME_2)

# regions that we don't expect to be missing according to the object ids
missing_regions_dont_expect_missing_objid <- missing_areas_drop_geom %>%
  filter(area_sans_units < 245.9) %>%
  pull(objectid) %>%
  as.vector()

# filtering based on the above criteria
foo <- regional_summary(colormap, pol_data_location, pop_raw_landscan_crop_pol, 0.001,missing_regions_dont_expect_missing_objid, 1998, 0.00833333)

#> filtering based on putting a constraint on the extent

# going in a loop through all missing regions and checking extents along the way and keeping only those that fit a certain criteria

# object id's that lie within 67.995 N and -54.995 S
rel_obj_ids <- c()

for (i in 1:nrow(missing_areas)){
  tmp_extent <- extent(missing_areas[i, ])
  if(((tmp_extent[3] < -54.995) | (tmp_extent[4] > 67.995) == TRUE)){
    next
  } else {
    rel_obj_ids[i] <- missing_areas[i, ]$objectid
  }
}
rel_obj_ids <- rel_obj_ids[!is.na(rel_obj_ids)]

# filtering based on the above criteria
foo <- regional_summary(colormap, pol_data_location, pop_raw_landscan_crop_pol, 0.001, rel_obj_ids, 1998, 0.00833333)

```

# combining the captured regions in a single file and appending it to the final gadm2 file, then recollapsing it to gadm1 and gadm 0

```{r eval=FALSE, include=FALSE}
#> read in the final gadm2 processed file for 2021 (shared with ViT)
gadm2_aqli_2021 <- read_csv("./ar.2023.update.using.2021.pol.data/data/output_vit/gadm2_aqli2021_vit.csv")

#> read in the 78 missing regions processed file (64 captured) and do some minor cleaning (rounding off the population interpolated column and rounding the pm column numbers to 2 decimal points)

# read in the missing regions file
missing_regions_processed <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/missing_regions_and_na_pop_regions_0.001_processed/78_missing_regions_processed.csv") 

# round the population column to the nearest integer (population data was interpolated by resampling population densities, hence we see some decimals)
missing_regions_processed$population <- round(missing_regions_processed$population)

# round the pm columns to a single decimal point
missing_regions_processed <- missing_regions_processed %>%
  dplyr::mutate(across(dplyr::matches("pm"), ~(round(.x, 1)), .names = "{col}"))


#> read in the 97 NA population processed file (20 captured) and do some minor cleaning (rounding off the population interpolated column and rounding the pm column numbers to 2 decimal points)

# read in the file
na_pop_regions_processed <- read_csv("./ar.2023.update.using.2021.pol.data/data/output/missing_regions_and_na_pop_regions_0.001_processed/97_na_population_resamp_0.001_processed.csv")

# round population data to the neareset integer (population data was interpolated by resampling population densities, hence we see some decimals)

na_pop_regions_processed$population <- round(na_pop_regions_processed$population)

# round the pm columns to a single decimal point

na_pop_regions_processed <- na_pop_regions_processed %>%
   dplyr::mutate(across(dplyr::matches("pm"), ~(round(.x, 1)), .names = "{col}"))

#> append the above 2 tables into a single table and getting rid where population  = 0

# bind rows
final_regions_toadd_df <- na_pop_regions_processed %>%
  bind_rows(missing_regions_processed)

# get rid of rows where population = 0
final_regions_toadd_df <- final_regions_toadd_df %>%
  filter(population != 0)

#> add national standards column

# read in the national standards file in the pipeline above

# adding the national standards column
final_regions_toadd_df <- final_regions_toadd_df %>%
  left_join(national_standards_pm2.5, by = "country") %>%
  select(objectid_gadm2:whostandard, natstandard_updated, dplyr::everything()) %>%
  rename(natstandard = natstandard_updated)

# replace natstandard == "No national standard", with NA, and then changing its data type to "numeric"
final_regions_toadd_df <- final_regions_toadd_df %>%
  dplyr::mutate(natstandard = ifelse(natstandard == "No national standard", NA, natstandard))

final_regions_toadd_df$natstandard <- as.numeric(final_regions_toadd_df$natstandard)

# adding in the life years lost relative to who and national standards column

# adding in the life years lost columns and doing some basic cleaning of column names to bring it into the format that we want, as per the AQLI data dictionary

final_regions_toadd_df <- final_regions_toadd_df %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who_{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat_{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm2, iso_alpha3, country, name_1, name_2, population, whostandard, natstandard, everything()) %>%
    dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 1)), .names = "{col}"))

# appending the above "to be added" regions back into the master gadm2_aqli_2021_vit file and then sorting by objectid_gadm2
gadm2_aqli_2021_with_added_regions <- gadm2_aqli_2021 %>%
  bind_rows(final_regions_toadd_df) %>%
  arrange(objectid_gadm2)

# collapsing the final gadm2 to gadm0

gadm0_aqli_2021_with_added_regions <- gadm2_aqli_2021_with_added_regions %>%
dplyr::group_by(country) %>%
dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                 total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
select(objectid_gadm2, iso_alpha3, country, total_population, whostandard, natstandard, dplyr::everything()) %>%
dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
dplyr::rename(population = total_population, 
              objectid_gadm0 = objectid_gadm2) %>%
dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who_{col}")) %>%
dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat_{col}")) %>%
dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
dplyr::select(objectid_gadm0, iso_alpha3, country, population, whostandard, natstandard, dplyr::everything()) %>%
dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 1)), .names = "{col}"))

# collapsing the final gadm2 to gadm1

gadm1_aqli_2021_with_added_regions <- gadm2_aqli_2021_with_added_regions %>%
  dplyr::group_by(country, name_1) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE)) %>%
  dplyr::mutate(across(dplyr::starts_with("pm"), ~(.x*pop_weights), .names = "{col}_pop_weighted")) %>%
  dplyr::summarise(across(dplyr::contains("pop_weighted"), ~(round(sum(.x, na.rm = TRUE), 2)), .names = "avg_{col}"),
                   total_population = sum(population, na.rm = TRUE), objectid_gadm2 = objectid_gadm2[1], iso_alpha3 = iso_alpha3[1], whostandard = whostandard[1], natstandard = natstandard[1]) %>%
  select(objectid_gadm2, iso_alpha3, country, name_1, total_population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::mutate(objectid_gadm2 = dplyr::row_number()) %>%
  dplyr::rename(population = total_population, 
                objectid_gadm1 = objectid_gadm2) %>%
  dplyr::rename_with(~str_replace_all(.x, "(_pop_weighted)|(avg_)", ""), dplyr::contains("_pop_weighted")) %>%
    dplyr::mutate(across(starts_with("pm"), (~(.x - whostandard)*aqli_lyl_constant), .names = "llpp_who_{col}")) %>%
  dplyr::mutate(across(starts_with("pm"), (~(.x - natstandard)*aqli_lyl_constant), .names = "llpp_nat_{col}")) %>%
  dplyr::mutate(across(starts_with("llpp"), ~ifelse(.x < 0, 0, .x))) %>%
  dplyr::mutate(across(starts_with("llpp_nat"), ~ifelse(natstandard == 0, NA, .x))) %>%
  dplyr::select(objectid_gadm1, iso_alpha3, country, name_1, population, whostandard, natstandard, dplyr::everything()) %>%
  dplyr::rename_with(~str_replace(.x, "pm", ""), dplyr::contains("llpp")) %>%
  dplyr::mutate(across(dplyr::matches("pm|llpp"), ~(round(.x, 1)), .names = "{col}"))



```


# Sanity checks area (deactivated for now)
```{r sanity_checks, eval=FALSE, include=FALSE}
#> sanity checks time-------------------------------------------------------------

#> 1: number of NA's in pollution for each colormap object id
foo <- arrow::open_dataset("D:/aqli.2023.report.data.share/2023.publish.year.with.2021.data/rasterized/0.008/1999.parquet/part-0.parquet")

# reading in the raw pollution raster for 1998
pol_raw_1998_tmp <- raster::raster(str_c(pol_data_location, "V5GL03.HybridPM25-NoDust-NoSeaSalt.Global.199801-199812.nc"))

pol_raw_2021_tmp <- raster::raster(str_c(pol_data_location, "V5GL03.HybridPM25-NoDust-NoSeaSalt.Global.202101-202112.nc"))

val_pol_raw_1998_tmp <- values(pol_raw_1998_tmp)
val_pol_raw_2021_tmp <- values(pol_raw_2021_tmp)


aqli_gadm2_collapse_na_summary <- foo %>%
  dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::summarise(count_rows = n(),
    total_nas_pol = sum(is.na(pm2.5_pollution)), 
    prop_na = round((total_nas_pol/count_rows)*100, 2)) 
  
#> 2: number of object ids for which we do not have any data
obj_id_missing <- which(colormap$objectid %notin% unique(aqli_gadm2_collapse_na_summary$colormap_objectid))

colormap %>%
  filter(objectid %in% obj_id_missing) %>% 
  st_write("./experimentation/missing_obj_ids.shp")

#> 3: number of NAs in population for each colormap object id
aqli_gadm2_collapse_na_summary_pop <- foo %>%
  dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::summarise(count_rows = n(),
    total_nas_pop = sum(is.na(population)), 
    prop_na = round((total_nas_pop/count_rows)*100, 2)) 

#> Counting the total number of pixels corresponding that are NAs

temp_1998 <- arrow::open_dataset("D:/aqli.2023.report.data.share/2023.publish.Year.with.2021.data/rasterized/0.008/1998.parquet/part-0.parquet", format = "parquet")

foo <- temp_1998 %>%
   group_by(colormap_objectid) %>%
  collect() %>%
  summarize(n = n())

#> comparing the parquet files for 0.008 resolution's 2013 and 1998 years
parquet_1998_0.008 <- arrow::open_dataset("D:/aqli.2023.report.data.share/2023.publish.year.with.2021.data/rasterized/0.008/1998.parquet/part-0.parquet")

parquet_1998_0.008_summary <- parquet_1998_0.008 %>%
    dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::summarise(count_rows = n(),
    total_nas_pol = sum(is.na(pm2.5_pollution)), 
    prop_na = round((total_nas_pol/count_rows)*100, 2)) 

parquet_2013_0.008 <- arrow::open_dataset("D:/aqli.2023.report.data.share/2023.publish.year.with.2021.data/rasterized/0.008/2013.parquet/part-0.parquet")

parquet_2013_0.008_summary <- parquet_2013_0.008 %>%
    dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::filter(colormap_objectid != "NA") %>%
  dplyr::summarise(count_rows = n(),
    total_nas_pol = sum(is.na(pm2.5_pollution)), 
    prop_na = round((total_nas_pol/count_rows)*100, 2)) 

#> comparing the parquet files (0.008 resolution) to see if filtering out NAs before collecting is faster than doing it after collecting data locally in R. Testing both for 2013 (which has NAs as "NA") and 1998 (which has NA as NA special value)

# 12 minutes
foo <- parquet_1998_0.008 %>%
    dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::filter((!is.na(colormap_objectid)) & (colormap_objectid != "NA")) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         pollution_pop_weighted = pop_weights*pm2.5_pollution) %>%
  dplyr::summarise(total_population = sum(population, na.rm = TRUE), 
            avg_pm2.5_pollution = sum(pollution_pop_weighted, na.rm = TRUE), 
            lyl_rel_who = round((avg_pm2.5_pollution - who_pm2.5_standard)*aqli_lyl_constant, 2), 
            lyl_rel_who = ifelse(lyl_rel_who < 0, 0, lyl_rel_who)) %>%
  dplyr::rename(objectid_gadm2 = colormap_objectid)

# 12 minutes
t1 <- Sys.time()
foo1 <- parquet_1998_0.008 %>%
    dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::filter((!is.na(colormap_objectid)) & (colormap_objectid != "NA")) %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         pollution_pop_weighted = pop_weights*pm2.5_pollution) %>%
  dplyr::summarise(total_population = sum(population, na.rm = TRUE), 
            avg_pm2.5_pollution = sum(pollution_pop_weighted, na.rm = TRUE)) %>%
  dplyr::rename(objectid_gadm2 = colormap_objectid)
t2 <- Sys.time()  

# 1.56 minutes to 3 minutes, wow!!! 
t3 <- Sys.time()
foo2 <- parquet_1998_0.008 %>%
   dplyr::filter((!is.na(colormap_objectid)) & ((as.character(colormap_objectid) != "NA"))) %>%
    dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         pollution_pop_weighted = pop_weights*pm2.5_pollution) %>%
  dplyr::summarise(total_population = sum(population, na.rm = TRUE), 
            avg_pm2.5_pollution = sum(pollution_pop_weighted, na.rm = TRUE)) %>%
  dplyr::rename(objectid_gadm2 = colormap_objectid)
t4 <- Sys.time()

# 4.62 minutes
t5 <- Sys.time()
foo2 <- parquet_1998_0.008 %>%
   dplyr::filter((!is.na(colormap_objectid)) & ((as.character(colormap_objectid) != "NA"))) %>%
  dplyr::group_by(colormap_objectid) %>%
  dplyr::collect() %>%
  dplyr::mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         pollution_pop_weighted = pop_weights*pm2.5_pollution) %>%
  dplyr::summarise(total_population = sum(population, na.rm = TRUE), 
            avg_pm2.5_pollution = sum(pollution_pop_weighted, na.rm = TRUE), 
            lyl_rel_who = round((avg_pm2.5_pollution - who_pm2.5_standard)*aqli_lyl_constant, 2), 
            lyl_rel_who = ifelse(lyl_rel_who < 0, 0, lyl_rel_who)) %>%
  dplyr::rename(objectid_gadm2 = colormap_objectid)
t6 <- Sys.time()

# gadm2 level final shapefile test and plot map

map1_global_aqli_color_scale_region_data <- aqli_gadm2_collapse_master_with_geom %>%
  mutate(lyl_aqli_bucket = ifelse((w2021 >= 0) & (w2021 < 0.1), "0 - < 0.1 years", NA), 
         lyl_aqli_bucket = ifelse((w2021 >= 0.1) & (w2021 < 0.5), "0.1 - < 0.5", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 0.5) & (w2021 < 1), "0.5 - < 1", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 1) & (w2021 < 2), "1 - < 2", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 2) & (w2021 < 3), "2 - < 3", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 3) & (w2021 < 4), "3 - < 4", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 4) & (w2021 < 5), "4 - < 5", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 5) & (w2021 < 6), "5 - < 6", lyl_aqli_bucket), 
         lyl_aqli_bucket = ifelse((w2021 >= 6), ">= 6 years", lyl_aqli_bucket)) %>%
  mutate(order_var = ifelse(lyl_aqli_bucket == "0 - < 0.1 years", 1, NA), 
         order_var = ifelse(lyl_aqli_bucket == "0.1 - < 0.5", 2, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "0.5 - < 1", 3, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "1 - < 2", 4, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "2 - < 3", 5, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "3 - < 4", 6, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "4 - < 5", 7, order_var), 
         order_var = ifelse(lyl_aqli_bucket == "5 - < 6", 8, order_var), 
         order_var = ifelse(lyl_aqli_bucket == ">= 6 years", 9, order_var)) 

# map1
map1_global_aqli_color_scale_updated_April102023 <- map1_global_aqli_color_scale_region_data %>%
  ggplot() +
  geom_sf(mapping = aes(fill = lyl_aqli_bucket), color = "transparent") +
  scale_fill_manual(values = c("0 - < 0.1 years" = "#FFFFFF", "0.1 - < 0.5" = "#FFE6B3", "0.5 - < 1" = "#FFD25D", 
                                "1 - < 2" = "#FFBA00", "2 - < 3" = "#FF9600", "3 - < 4" = "#FF6908", 
                                "4 - < 5" = "#E63D23", "5 - < 6" = "#BD251C", ">= 6 years" = "#8C130E")) +
  ggthemes::theme_map() +
  labs(fill = "Gain in years of Life Expectancy", title = "AQLI 2021 data: Life years lost") +
  theme(legend.position = "bottom", 
        plot.title = element_text(size = 15, hjust = 0.5), 
        legend.justification = c(0.5, 3), 
        plot.background = element_rect(fill = "aliceblue")) +
    guides(fill = guide_legend(nrow = 1)) 

ggsave(filename = "./aqli_global_2021_map_april102023_final.pdf", plot = map1_global_aqli_color_scale_updated_April102023, height = 14, width = 14)

# map2

#-------------------------------------------------------------------------------

# Taking a look at Al Qahirah, Egypt (sanity check suggested by Aaron)

egypt_missing_region_1 <- colormap %>% filter(NAME_0 == "Egypt", NAME_1 == "Al Qahirah", NAME_2 == "Bab ash-Sha'riyah") 

st_coordinates(egypt_missing_region_1)

# Taking a look at 2018 raw net cdf file
pol_2018_0.01_test <- raster::raster("./ar.2023.update.using.2021.pol.data/data/input/pollution/0.01x0.01/GWRPM25-NoDust-NoSeaSalt_0.01_0.01/GWRPM25-NoDust-NoSeaSalt/Annual/V5GL03.HybridPM25-NoDust-NoSeaSalt.Global.201801-201812.nc")

raster::crs(pol_2018_0.01_test) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84"

pol_2018_0.01_test_df <- raster::as.data.frame(pol_2018_0.01_test)

df_test <- tibble(lat = coordinates(pol_2018_0.01_test)[, 2], 
                  lon = coordinates(pol_2018_0.01_test)[, 1], 
                  pm2.5 = pol_2018_0.01_test_df$Hybrid.PM_2_._5.with.mineral.dust.and.seasalt.removed...mug.m.3.)

df_test1 <- arrow::open_dataset("./experimentation/df_test.parquet/part-0.parquet", format = "parquet")

df_test1_point <- df_test1 %>%
  dplyr::filter(lat >= 30, lat <= 30.07, lon >= 31.1, lon <= 31.3) %>%
  dplyr::collect()


df_test %>% arrow::write_dataset("./experimentation/df_test.parquet", format = "parquet")

# using nc package

pol_2018_0.01_test_nc_fun <- nc_open("./ar.2023.update.using.2021.pol.data/data/input/pollution/0.01x0.01/GWRPM25-NoDust-NoSeaSalt_0.01_0.01/GWRPM25-NoDust-NoSeaSalt/Annual/V5GL03.HybridPM25-NoDust-NoSeaSalt.Global.201801-201812.nc")


df_test <- tibble(latitude = lat, longitude = lon, pm2.5 = pol_2018_0.01_test_df$Hybrid.PM_2_._5.with.mineral.dust.and.seasalt.removed...mug.m.3.)

#> Sanity checks on the AQLI 2021 processed dataset

#- Comparing population column of color_2020 with the 2021 color file (gadm2)

# 2020 aqli data (read in the aqli dataset with which you want to compare the latest AQLI dataset)
color_2020 <- read_csv("./experimentation/color_2020.csv")

# 2021 aqli datasets (read in the latest available aqli dataset)
# aqli_gadm2_collapse_master <- read_csv(str_c(ssd_location_collapsed_gadm2_data_path, "master_global_allyears_gadm2_non_geom_Jan192023.csv"))
# 
# aqli_gadm0_collapse_from_gadm2 <- read_csv(str_c(ssd_location_collapsed_gadm0_data_path, "master_global_allyears_gadm0_non_geom_Jan192023.csv"))
# 
# aqli_gadm1_collapse_from_gadm2 <- read_csv(str_c(ssd_location_collapsed_gadm1_data_path, "master_global_allyears_gadm1_non_geom_Jan192023.csv"))

# joining 2020 gadm2 dataset with 2021 gadm2 dataset and comparing the population column
gadm2_2020_2021_pop_compare <- color_2020 %>% # 46702 rows
  select(country, name_1, name_2, population) %>%
  rename(population_old = population) %>%
  left_join(aqli_gadm2_collapse_master %>% select(country, name_1, name_2, population), by = c("country", "name_1", "name_2"))

# looking at a subset that contains only those rows in which we have a population number for both 2021 and 2020 data
gadm2_2020_2021_pop_compare_sub <- gadm2_2020_2021_pop_compare %>% # 42679 rows
  filter(!is.na(population_old) & !is.na(population)) 

# calculate pop difference b/w 2021 and 2020 gadm 2 level data
gadm2_2020_2021_pop_compare_sub <- gadm2_2020_2021_pop_compare_sub %>%
  mutate(pop_diff = population - population_old)

# For places, where population has decreased, plotting a distribution of abs(pop_diff). It seems like at max population has decreased by 10^5. Note that there were many border changes and regrouping of regions and shapefile updates. I personally don't think that its unreasonable. But still check
plt <- gadm2_2020_2021_pop_compare_sub %>%
filter(pop_diff < 0) %>%
  mutate(pop_diff_abs = abs(pop_diff)) %>%
  ggplot() +
  geom_density(mapping = aes(x = log10(pop_diff)), color = "black")

# comparing population distribution of color_2020 with color_2021
plt <- gadm2_2020_2021_pop_compare_sub %>%
  ggplot() +
  geom_histogram(mapping = aes(x = log10(population)), color = "white", fill = "cornflowerblue", alpha = 0.3) + 
  geom_histogram(mapping = aes(x = log10(population_old)), color = "white", fill = "red", alpha = 0.3) +
  ggtitle("Population difference distribution (pop 2021 - pop 2020)") +
  ggthemes::theme_clean()

# hist
plt <- gadm2_2020_2021_pop_compare_sub %>%
  ggplot() +
  geom_histogram(mapping = aes(x = pop_diff), color = "white") +
  scale_y_log10() + 
    ggtitle("Population difference distribution (pop 2021 - pop 2020)") +
  ggthemes::theme_clean()

#> check if any place (at gadm2/1/0) has a population of 0, yes: 97 places
pop_0_gadm2_regions <- aqli_gadm2_collapse_master %>%   # 97 regions
  filter(population == 0)

pop_0_gadm1_regions <- aqli_gadm1_collapse_from_gadm2 %>% # 27 regions
  filter(population == 0)

pop_0_gadm0_regions <- aqli_gadm0_collapse_from_gadm2 %>% # 6 regions 
  filter(population == 0)


# look for the above missing gadm2 regions in color_2020 file
color_2020 %>%
  filter(country %in% unique(pop_0_gadm2_regions$country), 
         name_1 %in% unique(pop_0_gadm2_regions$name_1), 
         name_2 %in% unique(pop_0_gadm2_regions$name_2)) %>%
  View()

# compare pm2.5 pollution distribution for 2020 v/s 2021 pollution data

plt <- color_2020 %>%
  filter(country == "United States") %>%
  ggplot() +
  geom_histogram(mapping = aes(x = pm2020), fill = "cornflowerblue", color = "white", alpha = 0.3) +
  geom_histogram(data = aqli_gadm2_collapse_master %>% filter(country == "United States"), mapping = aes(x = pm2020), fill = "red", color = "white", alpha = 0.3) 

# in places where there is 0 population at gadm level 2, is there pollution data available in the 2021 file and also in 2020 file. Answer: in 2020 it is available, but in 2021 no, because it probably was available, but went away when population weighting happened.

color_2020 %>%
  filter(country %in% pop_0_gadm2_regions$country, name_1 %in% pop_0_gadm2_regions$name_1, name_2 %in% pop_0_gadm2_regions$name_2) %>%
  View()

#> what country is not available in the collapsed gadm0 file, but is available in colormap
rel_ind <- unique(colormap$NAME_0) %notin% unique(aqli_gadm0_collapse_from_gadm2_with_geom$country)
unique(colormap$NAME_0)[rel_ind]

# the answer is "Svalbard and Jan Mayen", which comes under the list of regions we expect to be missing, because its outside the thresholds for which pollution data is available.

#> check the dimensions of each year's dataset and also check if all of the above sanity checks hold true in each year's dataset. 
 
#> See if there is a way to process the islands data in a special way, so that their population doesn't end up being 0.

#> plot timeseries/heatmap of last 24 years country wise and compare with old data counterpart heatmaps
 

country_graph <- "Pakistan"

#> trendlines, country wise compare 2020 v/s 2021 data
plt1_region <- aqli_gadm2_collapse_master %>%
  filter(country == country_graph) %>%
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         mutate(across(starts_with("pm"), ~.x*pop_weights, .names = "{col}_weighted"))) %>%
  summarise(across(ends_with("weighted"), sum)) %>%
  pivot_longer(cols = pm1998_weighted:pm2021_weighted, names_to = "years", 
               values_to = "pop_weighted_avg_pm2.5") %>%
  mutate(years = as.integer(unlist(str_extract(years, "\\d+"))), 
         region = "National Average") %>% 
  select(years, region, pop_weighted_avg_pm2.5) %>%
  ggplot() +
  geom_line(mapping = ggplot2::aes(x = as.integer(years), y = as.double(pop_weighted_avg_pm2.5)), lwd = 1.1, 
            color = "darkred") +
scale_y_continuous(breaks = seq(0, 60, 5), limits = c(0, 60)) +
  scale_x_continuous(breaks = seq(1998, 2020, 2))  +
  ggthemes::theme_clean() +
  labs(x = "Years", 
       y = expression(paste("Average PM2.5 concentration ( ", mu, "g", "/", m^3, " )")), 
       title = str_c("PM2.5 Pollution trend 1998 to 2021 (", country_graph, ")" )) +
  theme(legend.position = "bottom", legend.title = element_blank(), 
        legend.text = element_text(size = 7), 
        axis.title.y = element_text(size = 9), 
        axis.title.x = element_text(size = 9), 
        axis.text.x = element_text(size = 6), 
        axis.text.y = element_text(size = 6)) 
  # geom_text(x = 2002.8, y = 8.7, label = expression(paste("WHO PM2.5 Guideline (last updated: 2021): 5 ", mu, "g","/", m^3, "")))


plt0_region <- color_2020 %>%
  filter(country == country_graph) %>%
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         mutate(across(starts_with("pm"), ~.x*pop_weights, .names = "{col}_weighted"))) %>%
  summarise(across(ends_with("weighted"), sum)) %>%
  pivot_longer(cols = pm1998_weighted:pm2020_weighted, names_to = "years", 
               values_to = "pop_weighted_avg_pm2.5") %>%
  mutate(years = as.integer(unlist(str_extract(years, "\\d+"))), 
         region = "National Average") %>% 
  select(years, region, pop_weighted_avg_pm2.5) %>%
  ggplot() +
  geom_line(mapping = ggplot2::aes(x = as.integer(years), y = as.double(pop_weighted_avg_pm2.5)), lwd = 1.1, 
            color = "darkred") +
scale_y_continuous(breaks = seq(0, 60, 5), limits = c(0, 60)) +
  scale_x_continuous(breaks = seq(1998, 2020, 2))  +
  ggthemes::theme_clean() +
  labs(x = "Years", 
       y = expression(paste("Average PM2.5 concentration ( ", mu, "g", "/", m^3, " )")), 
       title = str_c("PM2.5 Pollution trend 1998 to 2020 (", country_graph, ")" )) +
  theme(legend.position = "bottom", legend.title = element_blank(), 
        legend.text = element_text(size = 7), 
        axis.title.y = element_text(size = 9), 
        axis.title.x = element_text(size = 9), 
        axis.text.x = element_text(size = 6), 
        axis.text.y = element_text(size = 6)) 

plt_region <- grid.arrange(plt0_region, plt1_region, nrow = 1)
 
#> heatmap continent wise

# read in continent-country mapping file
country_continent <- read_csv("./experimentation/others/country_continent.csv")

color_2020 <- color_2020 %>%
  left_join(country_continent, by = c("country"))

aqli_gadm2_collapse_master_continent <-  aqli_gadm2_collapse_master %>%
  left_join(country_continent, by = c("country"))

country_wise_pm2.5_average_2020_data <- color_2020  %>%
  filter(continent == "Africa") %>%
  group_by(country) %>%
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         mutate(across(starts_with("pm"), ~.x*pop_weights, .names = "{col}_weighted"))) %>%
  summarise(across(ends_with("weighted"), sum)) %>%
  pivot_longer(cols = pm1998_weighted:pm2020_weighted, names_to = "years", 
               values_to = "pop_weighted_avg_pm2.5") %>%
  mutate(years = as.integer(unlist(str_extract(years, "\\d+"))), 
         region = "National Average") %>% 
  arrange(pop_weighted_avg_pm2.5) 

country_wise_pm2.5_average <- aqli_gadm2_collapse_master_continent  %>%
  filter(continent == "Africa") %>%
  group_by(country) %>%
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         mutate(across(starts_with("pm"), ~.x*pop_weights, .names = "{col}_weighted"))) %>%
  summarise(across(ends_with("weighted"), sum)) %>%
  pivot_longer(cols = pm1998_weighted:pm2021_weighted, names_to = "years", 
               values_to = "pop_weighted_avg_pm2.5") %>%
  mutate(years = as.integer(unlist(str_extract(years, "\\d+"))), 
         region = "National Average") %>% 
  arrange(pop_weighted_avg_pm2.5) 

africa_countries_sample <- c("Democratic Republic of the Congo", 
                        "Rwanda", 
                        "Burundi", 
                        "Cameroon", 
                        "Uganda", 
                        "Angola", 
                        "Benin", 
                        "Ghana", 
                        "Gabon",
                        "Burkina Faso",
                        "South Africa",
                        "Egypt", 
                        "Libya",
                        "Niger", 
                        "Mauritius")


asia_countries_sample <- c("India", "China", "Indonesia", "Pakistan", "Afghanistan", "Myanmar", "Brunei")

heatmap_region_2020 <- country_wise_pm2.5_average_2020_data %>%
  filter(country %in% africa_countries_sample) %>%
  mutate(le_lost = (pop_weighted_avg_pm2.5 - 5)*0.098, 
         le_lost = ifelse(le_lost < 0, 0, le_lost)) %>%
  ggplot() +
  geom_raster(mapping = aes(x = years, y = fct_reorder(country, pop_weighted_avg_pm2.5), fill = pop_weighted_avg_pm2.5)) +
   scale_fill_viridis_b(option = "rocket", direction = -1) +
  scale_x_continuous(breaks = seq(1998, 2020, 1)) +
  labs(x = "Years", y = "", fill = "PM2.5 pollution (g/m)", caption = str_wrap("*This graph displays the life years lost relative to the WHO PM2.5 guideline in all countries of the African continent (from 1998 to 2020)")) +
  ggthemes::theme_hc() +
  theme(axis.text.x = element_text(size = 5), 
        axis.text.y = element_text(size = 7)) 




heatmap_region_2021 <- country_wise_pm2.5_average %>%
  filter(country %in% africa_countries_sample) %>%
  mutate(le_lost = (pop_weighted_avg_pm2.5 - 5)*0.098, 
         le_lost = ifelse(le_lost < 0, 0, le_lost)) %>%
  ggplot() +
  geom_raster(mapping = aes(x = years, y = fct_reorder(country, pop_weighted_avg_pm2.5), fill = pop_weighted_avg_pm2.5)) +
   scale_fill_viridis_b(option = "rocket", direction = -1) +
  scale_x_continuous(breaks = seq(1998, 2021, 1)) +
  labs(x = "Years", y = "", fill = "PM2.5 pollution (g/m)", caption = str_wrap("*This graph displays the life years lost relative to the WHO PM2.5 guideline in all countries of the African continent (from 1998 to 2021)")) +
  ggthemes::theme_hc() +
  theme(axis.text.x = element_text(size = 5), 
        axis.text.y = element_text(size = 7)) 

heatmap_region_final <- grid.arrange(heatmap_region_2020, heatmap_region_2021, nrow = 1)
#> More sanity checks on the llpp columns calculations


```



# tmp 

```{r}
foo1 <- gadm2_aqli_2021 %>% 
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         foo = llpp_who_2020*pop_weights*population) %>% 
  summarise(sum_foo = sum(foo, na.rm = TRUE))

foo2 <- gadm2_aqli_2021 %>% 
  mutate(pop_weights = population/sum(population, na.rm = TRUE), 
         foo = llpp_who_2021*pop_weights*population) %>% 
  summarise(sum_foo = sum(foo, na.rm = TRUE))

```

